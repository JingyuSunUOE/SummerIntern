{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a10069-9e7e-404f-b388-2cab9bb12bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# dataset\n",
    "from twaidata.torchdatasets.in_ram_ds import MRISegmentation2DDataset, MRISegmentation3DDataset\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "\n",
    "# model\n",
    "from trustworthai.models.base_models.source_kinet import kiunet, reskiunet, densekiunet, kiunet3d\n",
    "from trustworthai.models.base_models.torchUNet import UNet, UNet3D\n",
    "from trustworthai.models.base_models.deepmedic import DeepMedic\n",
    "\n",
    "# augmentation and pretrain processing\n",
    "from trustworthai.utils.augmentation.standard_transforms import RandomFlip, GaussianBlur, GaussianNoise, \\\n",
    "                                                            RandomResizeCrop, RandomAffine, \\\n",
    "                                                            NormalizeImg, PairedCompose, LabelSelect, \\\n",
    "                                                            PairedCentreCrop, CropZDim\n",
    "# loss function\n",
    "from trustworthai.utils.losses_and_metrics.tversky_loss import TverskyLoss\n",
    "from trustworthai.utils.losses_and_metrics.misc_metrics import IOU\n",
    "from trustworthai.utils.losses_and_metrics.dice import dice, DiceMetric\n",
    "from trustworthai.utils.losses_and_metrics.dice_losses import DiceLoss, GeneralizedDiceLoss\n",
    "from trustworthai.utils.losses_and_metrics.power_jaccard_loss import PowerJaccardLoss\n",
    "from torch.nn import BCELoss, MSELoss\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262326ce-e2dc-4397-bf14-12b2efcca863",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3407\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73738d2e-68ae-433e-89df-6398d7bdab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/disk/scratch/s2208943/ipdis/preprep/out_data/collated/\"\n",
    "wmh_dir = root_dir + \"WMH_challenge_dataset/\"\n",
    "ed_dir = root_dir + \"EdData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "579ab2af-70ee-4de2-89d1-7c7ba82029d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = [\n",
    "            wmh_dir + d for d in [\"Singapore\", \"Utrecht\", \"GE3T\"]\n",
    "          ]\n",
    "# domains = [\n",
    "#             wmh_dir + d for d in [\"Singapore\", \"Utrecht\", \"GE3T\"]\n",
    "#           ] + [\n",
    "#             ed_dir + d for d in [\"domainA\", \"domainB\", \"domainC\", \"domainD\"]\n",
    "#           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9dc92fea-1362-412e-8e76-3b8ad957ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do train validate test split\n",
    "test_proportion = 0.1\n",
    "validation_proportion = 0.2\n",
    "\n",
    "def train_val_test_split(dataset, val_prop, test_prop, seed):\n",
    "    # I think the sklearn version might be prefereable for determinism and things\n",
    "    # but that involves fiddling with the dataset implementation I think....\n",
    "    size = len(dataset)\n",
    "    test_size = int(test_prop*size) \n",
    "    val_size = int(val_prop*size)\n",
    "    train_size = size - val_size - test_size\n",
    "    train, val, test = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "68a9e622-487f-4008-8bae-57f8d3613276",
   "metadata": {},
   "outputs": [],
   "source": [
    "is3D = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8377ac18-41e3-49d0-ba6a-9daa1759074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation definintion\n",
    "def get_transforms(is3D):\n",
    "    transforms = [\n",
    "        LabelSelect(label_id=1),\n",
    "        RandomFlip(p=0.5, orientation=\"horizontal\"),\n",
    "        # GaussianBlur(p=0.5, kernel_size=7, sigma=(.1, 1.5)),\n",
    "        # GaussianNoise(p=0.2, mean=0, sigma=0.2),\n",
    "        # RandomAffine(p=0.2, shear=(.1,3.)),\n",
    "        # RandomAffine(p=0.2, degrees=5),\n",
    "        # RandomResizeCrop(p=1., scale=(0.6, 1.), ratio=(3./4., 4./3.))\n",
    "    ]\n",
    "    if not is3D:\n",
    "        return PairedCompose(transforms)\n",
    "    else:\n",
    "        transforms.append(CropZDim(size=32, minimum=0, maximum=-1))\n",
    "        return PairedCompose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca76fcb3-18ce-4c7e-bfd7-dc88f05d0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is3D:\n",
    "    transforms = CropZDim(size=32, minimum=0, maximum=-1)\n",
    "    datasets_domains = [MRISegmentation3DDataset(root_dir, domain, transforms=get_transforms(is3D)) for domain in domains]\n",
    "else:\n",
    "    datasets_domains = [MRISegmentation2DDataset(root_dir, domain, transforms=get_transforms(is3D)) for domain in domains]\n",
    "\n",
    "# split into train, val test datasets\n",
    "datasets = [train_val_test_split(dataset, validation_proportion, test_proportion, seed) for dataset in datasets_domains]\n",
    "\n",
    "# concat the train val test datsets\n",
    "train_dataset = ConcatDataset([ds[0] for ds in datasets])\n",
    "val_dataset = ConcatDataset([ds[1] for ds in datasets])\n",
    "test_dataset = ConcatDataset([ds[2] for ds in datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67e7a62b-0ed1-4990-adfd-269aec229daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2506, 716, 358)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c845ad1f-4ceb-4c09-b1db-f8a502b57d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 16, shuffle=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00ac1b-5f7d-4de9-bbd2-081e3be6bcec",
   "metadata": {},
   "source": [
    "### setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3cbfa0f8-e105-47db-98aa-0c58dbe0eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels = 1\n",
    "# TODO: put in the path to the assets on your machine here\n",
    "checkpoint_dir = \"/home/s2208943/ipdis/Trustworthai-MRI-WMH/assets/\"\n",
    "\n",
    "if is3D:\n",
    "    model = UNet3D(in_channels, out_channels, init_features=16, dropout_p=0., softmax=False)\n",
    "    checkpoint = checkpoint_dir + \"WMHCHAL_unet3d_16_no_softmax_dropout0.ckpt\"\n",
    "else:\n",
    "    model = UNet(in_channels, out_channels, init_features=32, dropout_p=0., softmax=False)\n",
    "    checkpoint = checkpoint_dir + \"WMHCHAL_unet2d_32_no_softmax_dropout0.ckpt\" \n",
    "    \n",
    "loss = GeneralizedDiceLoss(normalization='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08e44acc-395d-4489-ae30-38dba7ddc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StandardLitModelWrapper.load_from_checkpoint(checkpoint, model=model, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2464490b-ae45-47e9-9ccf-5567300ac516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "accelerator=\"gpu\"\n",
    "devices=1\n",
    "precision = 16\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    precision=precision,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c454d-6629-4e7e-b756-f772a16b2869",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f2a862d-71e5-46af-a8fd-9ffa343e2edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37dc2137dafa429ca716d3458bf89dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        val_loss            0.22884611785411835\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.22884611785411835}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b641744-de93-4b87-9e0c-5f92eeb93330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b6c3161f8d43289fd0dfe496879072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.24728116393089294\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.24728116393089294}]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd3208-8ac0-487f-b087-8733862c067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, datasets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95f1a0-f8c2-4188-99dd-3b96000fe0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ba1ae-cc2e-4b00-ac69-ca8bbbee9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get some predictions use trainer.predict(model, dataloader)\\s\n",
    "# remeber to use relevant normalization (e.g sigmoid or softmax) if it is not included in the model itself.\n",
    "\n",
    "# also note that the crop z dim transform by defualt takes a random range of slices from the 3D image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b062fc-169a-4321-8329-6ff284fe6b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some predictions\n",
    "x, y = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e451a-a5e1-4089-9281-7414602424ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930acf5-75ee-4f10-977e-f402341a7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = preds[0] # select first batch from predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb9def-f15a-4286-9bbb-dc5f54801f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1aab2-3a53-4cbf-bcfc-588bd415967a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
