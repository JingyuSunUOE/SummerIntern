{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a30ac-ab1c-47fd-b725-1e8719756516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# dataset\n",
    "from twaidata.torchdatasets.in_ram_ds import MRISegmentation2DDataset, MRISegmentation3DDataset\n",
    "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
    "\n",
    "# model\n",
    "from trustworthai.models.base_models.source_kinet import kiunet, reskiunet, densekiunet, kiunet3d\n",
    "from trustworthai.models.base_models.torchUNet import UNet, UNet3D\n",
    "from trustworthai.models.base_models.deepmedic import DeepMedic\n",
    "\n",
    "# augmentation and pretrain processing\n",
    "from trustworthai.utils.augmentation.standard_transforms import RandomFlip, GaussianBlur, GaussianNoise, \\\n",
    "                                                            RandomResizeCrop, RandomAffine, \\\n",
    "                                                            NormalizeImg, PairedCompose, LabelSelect, \\\n",
    "                                                            PairedCentreCrop, CropZDim\n",
    "# loss function\n",
    "from trustworthai.utils.losses_and_metrics.tversky_loss import TverskyLoss\n",
    "from trustworthai.utils.losses_and_metrics.misc_metrics import IOU\n",
    "from trustworthai.utils.losses_and_metrics.dice import dice, DiceMetric\n",
    "from trustworthai.utils.losses_and_metrics.dice_losses import DiceLoss, GeneralizedDiceLoss\n",
    "from trustworthai.utils.losses_and_metrics.power_jaccard_loss import PowerJaccardLoss\n",
    "from torch.nn import BCELoss, MSELoss, BCEWithLogitsLoss\n",
    "\n",
    "# fitter\n",
    "from trustworthai.utils.fitting_and_inference.fitters.basic_lightning_fitter import StandardLitModelWrapper\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e3f18-0236-4cf8-8e26-e76661200c01",
   "metadata": {},
   "source": [
    "### Set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450935a-a087-4b81-816b-cd4397db8680",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3407\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd568d-9fc6-4868-9d4a-617163ae6e9e",
   "metadata": {},
   "source": [
    "### define datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f9272-0a3b-4670-8880-82f04714d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "is3D = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91099153-5471-4603-8d5e-f8079445aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/disk/scratch/s2208943/ipdis/preprep/out_data/collated/\"\n",
    "wmh_dir = root_dir + \"WMH_challenge_dataset/\"\n",
    "ed_dir = root_dir + \"EdData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6f9d9-dd1d-411f-a85b-26a3d82cc48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = [\n",
    "            wmh_dir + d for d in [\"Singapore\", \"Utrecht\", \"GE3T\"]\n",
    "          ]\n",
    "\n",
    "# domains = [\n",
    "#             wmh_dir + d for d in [\"Singapore\", \"Utrecht\", \"GE3T\"]\n",
    "#           ] + [\n",
    "#             ed_dir + d for d in [\"domainA\", \"domainB\", \"domainC\", \"domainD\"]\n",
    "#           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c807e6-40f1-48bc-aed7-d395b569b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation definintion\n",
    "def get_transforms(is_3D):\n",
    "    transforms = [\n",
    "        LabelSelect(label_id=1),\n",
    "        RandomFlip(p=0.5, orientation=\"horizontal\"),\n",
    "        # GaussianBlur(p=0.5, kernel_size=7, sigma=(.1, 1.5)),\n",
    "        # GaussianNoise(p=0.2, mean=0, sigma=0.2),\n",
    "        # RandomAffine(p=0.2, shear=(.1,3.)),\n",
    "        # RandomAffine(p=0.2, degrees=5),\n",
    "        # RandomResizeCrop(p=1., scale=(0.6, 1.), ratio=(3./4., 4./3.))\n",
    "    ]\n",
    "    if not is_3D:\n",
    "        return PairedCompose(transforms)\n",
    "    else:\n",
    "        transforms.append(CropZDim(size=32, minimum=0, maximum=-1))\n",
    "        return PairedCompose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417fb72-4419-456d-b5ce-e14f0591651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do train validate test split\n",
    "test_proportion = 0.1\n",
    "validation_proportion = 0.2\n",
    "\n",
    "def train_val_test_split(dataset, val_prop, test_prop, seed):\n",
    "    # I think the sklearn version might be prefereable for determinism and things\n",
    "    # but that involves fiddling with the dataset implementation I think....\n",
    "    size = len(dataset)\n",
    "    test_size = int(test_prop*size) \n",
    "    val_size = int(val_prop*size)\n",
    "    train_size = size - val_size - test_size\n",
    "    train, val, test = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c247d-2265-4012-bc80-a92b4f2adec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "# this step is quite slow, all the data is being loaded into memory\n",
    "if is3D:\n",
    "    datasets_domains = [MRISegmentation3DDataset(root_dir, domain, transforms=get_transforms(is_3D=True)) for domain in domains]\n",
    "else:\n",
    "    datasets_domains = [MRISegmentation2DDataset(root_dir, domain, transforms=get_transforms(is_3D=False)) for domain in domains]\n",
    "\n",
    "# split into train, val test datasets\n",
    "datasets = [train_val_test_split(dataset, validation_proportion, test_proportion, seed) for dataset in datasets_domains]\n",
    "\n",
    "# concat the train val test datsets\n",
    "train_dataset = ConcatDataset([ds[0] for ds in datasets])\n",
    "val_dataset = ConcatDataset([ds[1] for ds in datasets])\n",
    "test_dataset = ConcatDataset([ds[2] for ds in datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5844a-5c39-47ff-897e-ad36de855931",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe0f1c-3c76-4069-b698-d7dd2a9c67f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 16, shuffle=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71898c27-608d-4ad3-9375-7710bfeb23a5",
   "metadata": {},
   "source": [
    "### setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9f593-6e8a-4c26-b9de-0ae024870248",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels = 1\n",
    "\n",
    "if is3D:\n",
    "    model = UNet3D(in_channels, out_channels, init_features=16, dropout_p=0., softmax=False)\n",
    "    optimizer_params={\"lr\":2e-3}, lr_scheduler_params={\"step_size\":100, \"gamma\":0.5}\n",
    "else:\n",
    "    model = UNet(in_channels, out_channels, init_features=32, dropout_p=0., softmax=False)\n",
    "    optimizer_params={\"lr\":1e-3}, lr_scheduler_params={\"step_size\":30, \"gamma\":0.1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d139f55-4aa6-4a99-94e6-212d88d6e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = GeneralizedDiceLoss(normalization='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ae5da-3073-4c42-86b1-753fc874b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StandardLitModelWrapper(model, loss, optimizer_params=optimizer_params, lr_scheduler_params=lr_scheduler_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b2864-efcf-4e7b-bbd8-ea20000f128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/disk/scratch/s2208943/results/\"\n",
    "strategy = None\n",
    "# strategy = \"deepspeed_stage_2\"\n",
    "# strategy = \"dp\"\n",
    "#strategy = \"deepspeed_stage_2_offload\"\n",
    "\n",
    "accelerator=\"gpu\"\n",
    "devices=1\n",
    "max_epochs=1000\n",
    "precision = 16\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_dir, save_top_k=2, monitor=\"val_loss\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=100, verbose=\"False\", mode=\"min\", check_finite=True)\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    max_epochs=max_epochs,\n",
    "    strategy=strategy,\n",
    "    precision=precision,\n",
    "    default_root_dir=checkpoint_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de0353-be84-4764-b89e-8326d6d2b021",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b84231-df5d-4cb4-ae82-2dc586ebb311",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50feb889-67c0-4d89-818a-159ff7e3daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model, val_dataloader, ckpt_path=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c62ef-4e59-4026-8199-c53074d05deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
