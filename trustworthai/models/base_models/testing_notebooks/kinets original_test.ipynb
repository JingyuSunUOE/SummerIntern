{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d651f3d9-3e34-4396-b65f-ce538173f52a",
   "metadata": {},
   "source": [
    "# testing model architectures\n",
    "check models compile okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60522491-a1b6-424f-bda9-9f4fdb2ed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aba427-5816-44de-8422-5ad0463cd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kiunet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.encoder1 = nn.Conv2d(1, 16, 3, stride=1, padding=1)  # First Layer GrayScale Image , change to input channels to 3 in case of RGB \n",
    "        self.en1_bn = nn.BatchNorm2d(16)\n",
    "        self.encoder2=   nn.Conv2d(16, 32, 3, stride=1, padding=1)  \n",
    "        self.en2_bn = nn.BatchNorm2d(32)\n",
    "        self.encoder3=   nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.en3_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.decoder1 =   nn.Conv2d(64, 32, 3, stride=1, padding=1)   \n",
    "        self.de1_bn = nn.BatchNorm2d(32)\n",
    "        self.decoder2 =   nn.Conv2d(32,16, 3, stride=1, padding=1)\n",
    "        self.de2_bn = nn.BatchNorm2d(16)\n",
    "        self.decoder3 =   nn.Conv2d(16, 8, 3, stride=1, padding=1)\n",
    "        self.de3_bn = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.decoderf1 =   nn.Conv2d(64, 32, 3, stride=1, padding=1)\n",
    "        self.def1_bn = nn.BatchNorm2d(32)\n",
    "        self.decoderf2=   nn.Conv2d(32, 16, 3, stride=1, padding=1)\n",
    "        self.def2_bn = nn.BatchNorm2d(16)\n",
    "        self.decoderf3 =   nn.Conv2d(16, 8, 3, stride=1, padding=1)\n",
    "        self.def3_bn = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.encoderf1 =   nn.Conv2d(1, 16, 3, stride=1, padding=1)  # First Layer GrayScale Image , change to input channels to 3 in case of RGB \n",
    "        self.enf1_bn = nn.BatchNorm2d(16)\n",
    "        self.encoderf2=   nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "        self.enf2_bn = nn.BatchNorm2d(32)\n",
    "        self.encoderf3 =   nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.enf3_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.intere1_1 = nn.Conv2d(16,16,3, stride=1, padding=1)\n",
    "        self.inte1_1bn = nn.BatchNorm2d(16)\n",
    "        self.intere2_1 = nn.Conv2d(32,32,3, stride=1, padding=1)\n",
    "        self.inte2_1bn = nn.BatchNorm2d(32)\n",
    "        self.intere3_1 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.inte3_1bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.intere1_2 = nn.Conv2d(16,16,3, stride=1, padding=1)\n",
    "        self.inte1_2bn = nn.BatchNorm2d(16)\n",
    "        self.intere2_2 = nn.Conv2d(32,32,3, stride=1, padding=1)\n",
    "        self.inte2_2bn = nn.BatchNorm2d(32)\n",
    "        self.intere3_2 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.inte3_2bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.interd1_1 = nn.Conv2d(32,32,3, stride=1, padding=1)\n",
    "        self.intd1_1bn = nn.BatchNorm2d(32)\n",
    "        self.interd2_1 = nn.Conv2d(16,16,3, stride=1, padding=1)\n",
    "        self.intd2_1bn = nn.BatchNorm2d(16)\n",
    "        self.interd3_1 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.intd3_1bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.interd1_2 = nn.Conv2d(32,32,3, stride=1, padding=1)\n",
    "        self.intd1_2bn = nn.BatchNorm2d(32)\n",
    "        self.interd2_2 = nn.Conv2d(16,16,3, stride=1, padding=1)\n",
    "        self.intd2_2bn = nn.BatchNorm2d(16)\n",
    "        self.interd3_2 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.intd3_2bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.final = nn.Conv2d(8,2,1,stride=1,padding=0)\n",
    "        \n",
    "        self.soft = nn.Softmax(dim =1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = F.relu(self.en1_bn(F.max_pool2d(self.encoder1(x),2,2)))  #U-Net branch\n",
    "        out1 = F.relu(self.enf1_bn(F.interpolate(self.encoderf1(x),scale_factor=(2,2),mode ='bilinear'))) #Ki-Net branch\n",
    "        \n",
    "        print(\"unet out shape:  \", out.shape)\n",
    "        print(\"kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        \n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.inte1_1bn(self.intere1_1(out1))),scale_factor=(0.25,0.25),mode ='bilinear')) #CRFB\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.inte1_2bn(self.intere1_2(tmp))),scale_factor=(4,4),mode ='bilinear')) #CRFB\n",
    "        print(\"post crfb unet out shape:  \", out.shape)\n",
    "        print(\"post crfb kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        u1 = out  #skip conn\n",
    "        o1 = out1  #skip conn\n",
    "\n",
    "        out = F.relu(self.en2_bn(F.max_pool2d(self.encoder2(out),2,2)))\n",
    "        out1 = F.relu(self.enf2_bn(F.interpolate(self.encoderf2(out1),scale_factor=(2,2),mode ='bilinear')))\n",
    "        \n",
    "        print(\"unet out shape:  \", out.shape)\n",
    "        print(\"kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        \n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.inte2_1bn(self.intere2_1(out1))),scale_factor=(0.0625,0.0625),mode ='bilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.inte2_2bn(self.intere2_2(tmp))),scale_factor=(16,16),mode ='bilinear'))\n",
    "        print(\"post crfb unet out shape:  \", out.shape)\n",
    "        print(\"post crfb kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        u2 = out\n",
    "        o2 = out1\n",
    "\n",
    "        out = F.relu(self.en3_bn(F.max_pool2d(self.encoder3(out),2,2)))\n",
    "        out1 = F.relu(self.enf3_bn(F.interpolate(self.encoderf3(out1),scale_factor=(2,2),mode ='bilinear')))\n",
    "        \n",
    "        print(\"unet out shape:  \", out.shape)\n",
    "        print(\"kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        \n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.inte3_1bn(self.intere3_1(out1))),scale_factor=(0.015625,0.015625),mode ='bilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.inte3_2bn(self.intere3_2(tmp))),scale_factor=(64,64),mode ='bilinear'))\n",
    "        print(\"post crfb unet out shape:  \", out.shape)\n",
    "        print(\"post crfb kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        ### End of encoder block\n",
    "\n",
    "        print(\"STARTING decoder\\n\")\n",
    "        ### Start Decoder\n",
    "        print(\"unet in hape\", out.shape)\n",
    "        print(\"kinet in shape\", out1.shape)\n",
    "        print()\n",
    "        \n",
    "        out = F.relu(self.de1_bn(F.interpolate(self.decoder1(out),scale_factor=(2,2),mode ='bilinear')))  #U-NET\n",
    "        out1 = F.relu(self.def1_bn(F.max_pool2d(self.decoderf1(out1),2,2))) #Ki-NET\n",
    "        print(\"unet out shape:  \", out.shape)\n",
    "        print(\"kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.intd1_1bn(self.interd1_1(out1))),scale_factor=(0.0625,0.0625),mode ='bilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.intd1_2bn(self.interd1_2(tmp))),scale_factor=(16,16),mode ='bilinear'))\n",
    "        print(\"\\nunet shape crfb 1\", out.shape)\n",
    "        print(\"kinet shape crfb 1\", out1.shape)\n",
    "        \n",
    "        out = torch.add(out,u2)  #skip conn\n",
    "        out1 = torch.add(out1,o2)  #skip conn\n",
    "        \n",
    "        print(\"unet skip out shape:  \", out.shape)\n",
    "        print(\"kinet skip out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        \n",
    "\n",
    "        out = F.relu(self.de2_bn(F.interpolate(self.decoder2(out),scale_factor=(2,2),mode ='bilinear')))\n",
    "        out1 = F.relu(self.def2_bn(F.max_pool2d(self.decoderf2(out1),2,2)))\n",
    "        \n",
    "        print(\"unet out shape:  \", out.shape)\n",
    "        print(\"kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        \n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.intd2_1bn(self.interd2_1(out1))),scale_factor=(0.25,0.25),mode ='bilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.intd2_2bn(self.interd2_2(tmp))),scale_factor=(4,4),mode ='bilinear'))\n",
    "        print(\"post crfb unet out shape:  \", out.shape)\n",
    "        print(\"post crfb kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "        \n",
    "        out = torch.add(out,u1)\n",
    "        out1 = torch.add(out1,o1)\n",
    "        \n",
    "        print(\"unet skip out shape:  \", out.shape)\n",
    "        print(\"kinet skip out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "\n",
    "        out = F.relu(self.de3_bn(F.interpolate(self.decoder3(out),scale_factor=(2,2),mode ='bilinear')))\n",
    "        out1 = F.relu(self.def3_bn(F.max_pool2d(self.decoderf3(out1),2,2)))\n",
    "\n",
    "        print(\"unet out shape:  \", out.shape)\n",
    "        print(\"kinet out shape: \", out1.shape)\n",
    "        print(\"------------------\\n\")\n",
    "\n",
    "        out = torch.add(out,out1) # fusion of both branches\n",
    "\n",
    "        out = F.relu(self.final(out))  #1*1 conv\n",
    "        \n",
    "\n",
    "        # out = self.soft(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad837a3-da75-49a2-8918-3ba00fc3ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiu = Kiunet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7267e932-d4fb-4f1a-a3a0-26b3f63dba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "post crfb unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "post crfb kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "post crfb unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "post crfb kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "unet out shape:   torch.Size([1, 64, 8, 8])\n",
      "kinet out shape:  torch.Size([1, 64, 512, 512])\n",
      "------------------\n",
      "\n",
      "post crfb unet out shape:   torch.Size([1, 64, 8, 8])\n",
      "post crfb kinet out shape:  torch.Size([1, 64, 512, 512])\n",
      "------------------\n",
      "\n",
      "STARTING decoder\n",
      "\n",
      "unet in hape torch.Size([1, 64, 8, 8])\n",
      "kinet in shape torch.Size([1, 64, 512, 512])\n",
      "\n",
      "unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "\n",
      "unet shape crfb 1 torch.Size([1, 32, 16, 16])\n",
      "kinet shape crfb 1 torch.Size([1, 32, 256, 256])\n",
      "unet skip out shape:   torch.Size([1, 32, 16, 16])\n",
      "kinet skip out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "post crfb unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "post crfb kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "unet skip out shape:   torch.Size([1, 16, 32, 32])\n",
      "kinet skip out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "unet out shape:   torch.Size([1, 8, 64, 64])\n",
      "kinet out shape:  torch.Size([1, 8, 64, 64])\n",
      "------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Kiunet                                   --                        --\n",
       "├─Conv2d: 1-1                            [1, 16, 64, 64]           160\n",
       "├─BatchNorm2d: 1-2                       [1, 16, 32, 32]           32\n",
       "├─Conv2d: 1-3                            [1, 16, 64, 64]           160\n",
       "├─BatchNorm2d: 1-4                       [1, 16, 128, 128]         32\n",
       "├─Conv2d: 1-5                            [1, 16, 128, 128]         2,320\n",
       "├─BatchNorm2d: 1-6                       [1, 16, 128, 128]         32\n",
       "├─Conv2d: 1-7                            [1, 16, 32, 32]           2,320\n",
       "├─BatchNorm2d: 1-8                       [1, 16, 32, 32]           32\n",
       "├─Conv2d: 1-9                            [1, 32, 32, 32]           4,640\n",
       "├─BatchNorm2d: 1-10                      [1, 32, 16, 16]           64\n",
       "├─Conv2d: 1-11                           [1, 32, 128, 128]         4,640\n",
       "├─BatchNorm2d: 1-12                      [1, 32, 256, 256]         64\n",
       "├─Conv2d: 1-13                           [1, 32, 256, 256]         9,248\n",
       "├─BatchNorm2d: 1-14                      [1, 32, 256, 256]         64\n",
       "├─Conv2d: 1-15                           [1, 32, 16, 16]           9,248\n",
       "├─BatchNorm2d: 1-16                      [1, 32, 16, 16]           64\n",
       "├─Conv2d: 1-17                           [1, 64, 16, 16]           18,496\n",
       "├─BatchNorm2d: 1-18                      [1, 64, 8, 8]             128\n",
       "├─Conv2d: 1-19                           [1, 64, 256, 256]         18,496\n",
       "├─BatchNorm2d: 1-20                      [1, 64, 512, 512]         128\n",
       "├─Conv2d: 1-21                           [1, 64, 512, 512]         36,928\n",
       "├─BatchNorm2d: 1-22                      [1, 64, 512, 512]         128\n",
       "├─Conv2d: 1-23                           [1, 64, 8, 8]             36,928\n",
       "├─BatchNorm2d: 1-24                      [1, 64, 8, 8]             128\n",
       "├─Conv2d: 1-25                           [1, 32, 8, 8]             18,464\n",
       "├─BatchNorm2d: 1-26                      [1, 32, 16, 16]           64\n",
       "├─Conv2d: 1-27                           [1, 32, 512, 512]         18,464\n",
       "├─BatchNorm2d: 1-28                      [1, 32, 256, 256]         64\n",
       "├─Conv2d: 1-29                           [1, 32, 256, 256]         9,248\n",
       "├─BatchNorm2d: 1-30                      [1, 32, 256, 256]         64\n",
       "├─Conv2d: 1-31                           [1, 32, 16, 16]           9,248\n",
       "├─BatchNorm2d: 1-32                      [1, 32, 16, 16]           64\n",
       "├─Conv2d: 1-33                           [1, 16, 16, 16]           4,624\n",
       "├─BatchNorm2d: 1-34                      [1, 16, 32, 32]           32\n",
       "├─Conv2d: 1-35                           [1, 16, 256, 256]         4,624\n",
       "├─BatchNorm2d: 1-36                      [1, 16, 128, 128]         32\n",
       "├─Conv2d: 1-37                           [1, 16, 128, 128]         2,320\n",
       "├─BatchNorm2d: 1-38                      [1, 16, 128, 128]         32\n",
       "├─Conv2d: 1-39                           [1, 16, 32, 32]           2,320\n",
       "├─BatchNorm2d: 1-40                      [1, 16, 32, 32]           32\n",
       "├─Conv2d: 1-41                           [1, 8, 32, 32]            1,160\n",
       "├─BatchNorm2d: 1-42                      [1, 8, 64, 64]            16\n",
       "├─Conv2d: 1-43                           [1, 8, 128, 128]          1,160\n",
       "├─BatchNorm2d: 1-44                      [1, 8, 64, 64]            16\n",
       "├─Conv2d: 1-45                           [1, 2, 64, 64]            18\n",
       "├─BatchNorm2d: 1-46                      --                        (recursive)\n",
       "├─Conv2d: 1-47                           --                        36,928\n",
       "├─BatchNorm2d: 1-48                      --                        128\n",
       "├─Conv2d: 1-49                           --                        (recursive)\n",
       "├─Softmax: 1-50                          --                        --\n",
       "==========================================================================================\n",
       "Total params: 253,602\n",
       "Trainable params: 253,602\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 17.45\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 633.62\n",
       "Params size (MB): 1.01\n",
       "Estimated Total Size (MB): 634.65\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(kiu, (1, 1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fde101dc-8ccb-4109-8cb8-65b7565b9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0748152-d780-4c66-9604-aac6b6d463ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68239141-c25f-4d20-81c0-8298ba855489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "post crfb unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "post crfb kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "post crfb unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "post crfb kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "unet out shape:   torch.Size([1, 64, 8, 8])\n",
      "kinet out shape:  torch.Size([1, 64, 512, 512])\n",
      "------------------\n",
      "\n",
      "post crfb unet out shape:   torch.Size([1, 64, 8, 8])\n",
      "post crfb kinet out shape:  torch.Size([1, 64, 512, 512])\n",
      "------------------\n",
      "\n",
      "STARTING decoder\n",
      "\n",
      "unet in hape torch.Size([1, 64, 8, 8])\n",
      "kinet in shape torch.Size([1, 64, 512, 512])\n",
      "\n",
      "unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "\n",
      "unet shape crfb 1 torch.Size([1, 32, 16, 16])\n",
      "kinet shape crfb 1 torch.Size([1, 32, 256, 256])\n",
      "unet skip out shape:   torch.Size([1, 32, 16, 16])\n",
      "kinet skip out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "post crfb unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "post crfb kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "unet skip out shape:   torch.Size([1, 16, 32, 32])\n",
      "kinet skip out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "unet out shape:   torch.Size([1, 8, 64, 64])\n",
      "kinet out shape:  torch.Size([1, 8, 64, 64])\n",
      "------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = kiu(x.to(\"cuda\")).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90fd0789-b951-4cbe-8bae-08e026599efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 64, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee0fa38e-7e5d-4e8e-97d4-d93ac4501391",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kiunet3d(nn.Module): #\n",
    "\n",
    "    def __init__(self, c=4,n=1,channels=128,groups = 16,norm='bn', num_classes=5):\n",
    "        super(kiunet3d, self).__init__()\n",
    "\n",
    "        # Entry flow\n",
    "        self.encoder1 = nn.Conv3d( c, n, kernel_size=3, padding=1, stride=1, bias=False)# H//2\n",
    "        self.encoder2 = nn.Conv3d( n, 2*n, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.encoder3 = nn.Conv3d( 2*n, 4*n, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        \n",
    "        self.kencoder1 = nn.Conv3d( c, n, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.kencoder2 = nn.Conv3d( n, 2*n, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.kencoder3 = nn.Conv3d( 2*n, 2*n, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "\n",
    "        self.downsample1 = nn.MaxPool3d(2, stride=2)\n",
    "        self.downsample2 = nn.MaxPool3d(2, stride=2)\n",
    "        self.downsample3 = nn.MaxPool3d(2, stride=2)\n",
    "        self.kdownsample1 = nn.MaxPool3d(2, stride=2)\n",
    "        self.kdownsample2 = nn.MaxPool3d(2, stride=2)\n",
    "        self.kdownsample3 = nn.MaxPool3d(2, stride=2)\n",
    "        \n",
    "\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False) # H//8        \n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False) # H//4\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False) # H//2\n",
    "        self.kupsample1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False) # H//8        \n",
    "        self.kupsample2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False) # H//4\n",
    "        self.kupsample3 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False) # H//2\n",
    "        \n",
    "        self.decoder1 = nn.Conv3d( 4*n, 2*n, kernel_size=3, padding=1, stride=1, bias=False)        \n",
    "        self.decoder2 = nn.Conv3d( 2*n, 2*n, kernel_size=3, padding=1, stride=1, bias=False)        \n",
    "        self.decoder3 = nn.Conv3d( 2*n, c, kernel_size=3, padding=1, stride=1, bias=False)        \n",
    "        self.kdecoder1 = nn.Conv3d( 2*n, 2*n, kernel_size=3, padding=1, stride=1, bias=False)        \n",
    "        self.kdecoder2 = nn.Conv3d( 2*n, 2*n, kernel_size=3, padding=1, stride=1, bias=False)        \n",
    "        self.kdecoder3 = nn.Conv3d( 2*n, c, kernel_size=3, padding=1, stride=1, bias=False)        \n",
    "        \n",
    "        self.intere1_1 = nn.Conv3d(n,n,3, stride=1, padding=1)\n",
    "        # self.inte1_1bn = nn.BatchNorm2d(16)\n",
    "        self.intere2_1 = nn.Conv3d(2*n,2*n,3, stride=1, padding=1)\n",
    "        # self.inte2_1bn = nn.BatchNorm2d(32)\n",
    "        self.intere3_1 = nn.Conv3d(2*n,4*n,3, stride=1, padding=1)\n",
    "        # self.inte3_1bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.intere1_2 = nn.Conv3d(n,n,3, stride=1, padding=1)\n",
    "        # self.inte1_2bn = nn.BatchNorm2d(16)\n",
    "        self.intere2_2 = nn.Conv3d(2*n,2*n,3, stride=1, padding=1)\n",
    "        # self.inte2_2bn = nn.BatchNorm2d(32)\n",
    "        self.intere3_2 = nn.Conv3d(4*n,2*n,3, stride=1, padding=1)\n",
    "        # self.inte3_2bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.interd1_1 = nn.Conv3d(2*n,2*n,3, stride=1, padding=1)\n",
    "        # self.intd1_1bn = nn.BatchNorm2d(32)\n",
    "        self.interd2_1 = nn.Conv3d(2*n,2*n,3, stride=1, padding=1)\n",
    "        # self.intd2_1bn = nn.BatchNorm2d(16)\n",
    "        self.interd3_1 = nn.Conv3d(n,n,3, stride=1, padding=1)\n",
    "        # self.intd3_1bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.interd1_2 = nn.Conv3d(2*n,2*n,3, stride=1, padding=1)\n",
    "        # self.intd1_2bn = nn.BatchNorm2d(32)\n",
    "        self.interd2_2 = nn.Conv3d(2*n,2*n,3, stride=1, padding=1)\n",
    "        # self.intd2_2bn = nn.BatchNorm2d(16)\n",
    "        self.interd3_2 = nn.Conv3d(n,n,3, stride=1, padding=1)\n",
    "        # self.intd3_2bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.seg = nn.Conv3d(c, num_classes, kernel_size=1, padding=0,stride=1,bias=False)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # Initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                torch.nn.init.torch.nn.init.kaiming_normal_(m.weight) #\n",
    "            elif isinstance(m, nn.BatchNorm3d) or isinstance(m, nn.GroupNorm):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        out = F.relu(F.max_pool3d(self.encoder1(x),2,2))  #U-Net branch\n",
    "        out1 = F.relu(F.interpolate(self.kencoder1(x),scale_factor=2,mode ='trilinear')) #Ki-Net branch\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.intere1_1(out1)),scale_factor=0.25,mode ='trilinear')) #CRFB\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.intere1_2(tmp)),scale_factor=4,mode ='trilinear')) #CRFB\n",
    "        \n",
    "        u1 = out  #skip conn\n",
    "        o1 = out1  #skip conn\n",
    "\n",
    "        out = F.relu(F.max_pool3d(self.encoder2(out),2,2))\n",
    "        out1 = F.relu(F.interpolate(self.kencoder2(out1),scale_factor=2,mode ='trilinear'))\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.intere2_1(out1)),scale_factor=0.0625,mode ='trilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.intere2_2(tmp)),scale_factor=16,mode ='trilinear'))\n",
    "        \n",
    "        u2 = out\n",
    "        o2 = out1\n",
    "\n",
    "        out = F.relu(F.max_pool3d(self.encoder3(out),2,2))\n",
    "        out1 = F.relu(F.interpolate(self.kencoder3(out1),scale_factor=2,mode ='trilinear'))\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.intere3_1(out1)),scale_factor=0.015625,mode ='trilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.intere3_2(tmp)),scale_factor=64,mode ='trilinear'))\n",
    "        \n",
    "        ### End of encoder block\n",
    "\n",
    "        ### Start Decoder\n",
    "        \n",
    "        out = F.relu(F.interpolate(self.decoder1(out),scale_factor=2,mode ='trilinear'))  #U-NET\n",
    "        out1 = F.relu(F.max_pool3d(self.kdecoder1(out1),2,2)) #Ki-NET\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.interd1_1(out1)),scale_factor=0.0625,mode ='trilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.interd1_2(tmp)),scale_factor=16,mode ='trilinear'))\n",
    "        \n",
    "        out = torch.add(out,u2)  #skip conn\n",
    "        out1 = torch.add(out1,o2)  #skip conn\n",
    "\n",
    "        out = F.relu(F.interpolate(self.decoder2(out),scale_factor=2,mode ='trilinear'))\n",
    "        out1 = F.relu(F.max_pool3d(self.kdecoder2(out1),2,2))\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.interd2_1(out1)),scale_factor=0.25,mode ='trilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.interd2_2(tmp)),scale_factor=4,mode ='trilinear'))\n",
    "        \n",
    "        out = torch.add(out,u1)\n",
    "        out1 = torch.add(out1,o1)\n",
    "\n",
    "        out = F.relu(F.interpolate(self.decoder3(out),scale_factor=2,mode ='trilinear'))\n",
    "        out1 = F.relu(F.max_pool3d(self.kdecoder3(out1),2,2))\n",
    "\n",
    "        \n",
    "\n",
    "        out = torch.add(out,out1) # fusion of both branches\n",
    "\n",
    "        out = F.relu(self.seg(out))  #1*1 conv\n",
    "        \n",
    "\n",
    "        # out = self.soft(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5476f5ee-1c6d-4777-a01d-0db7db398e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "net3d = kiunet3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d3e86b5-f2fa-4dbb-b0e2-6cdf05132312",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/torchinfo/torchinfo.py:294\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 294\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mkiunet3d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Encoder\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(F\u001b[38;5;241m.\u001b[39mmax_pool3d(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m#U-Net branch\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     out1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(F\u001b[38;5;241m.\u001b[39minterpolate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkencoder1(x),scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,mode \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m#Ki-Net branch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/torch/nn/modules/module.py:1128\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1128\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/torch/nn/modules/conv.py:592\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/torch/nn/modules/conv.py:587\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    577\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    578\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    586\u001b[0m     )\n\u001b[0;32m--> 587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 4, 3, 3, 3], expected input[1, 2, 25, 64, 64] to have 4 channels, but got 2 channels instead",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet3d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/torchinfo/torchinfo.py:215\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m validate_user_params(\n\u001b[1;32m    209\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    212\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    213\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    214\u001b[0m )\n\u001b[0;32m--> 215\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    219\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    220\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    221\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ip/lib/python3.9/site-packages/torchinfo/torchinfo.py:303\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    302\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "summary(net3d, (1, 2, 25, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdc6f36-0a08-4f65-873b-1ed39d84ebdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
