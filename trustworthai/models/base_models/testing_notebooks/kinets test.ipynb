{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d651f3d9-3e34-4396-b65f-ce538173f52a",
   "metadata": {},
   "source": [
    "# testing model architectures\n",
    "check models compile okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60522491-a1b6-424f-bda9-9f4fdb2ed985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39570497-5052-4501-9126-463b367803bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustworthai.models.base_models.kiUNets import SimpleBlock, FullyConvolutionalAutoEncoder, KiUNetWithTranspose, KiUNet3D, block_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691c9554-e171-4de9-8d37-596fdc7f241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_block = SimpleBlock(2, 32, 3, 0.1, False, True, dimensions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1d95ee-d8a3-4b61-ba5c-a3394a8c8153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleBlock                              --                        --\n",
       "├─Conv3d: 1-1                            [1, 32, 48, 128, 128]     1,760\n",
       "├─BatchNorm3d: 1-2                       [1, 32, 24, 64, 64]       64\n",
       "├─Dropout3d: 1-3                         [1, 32, 24, 64, 64]       --\n",
       "==========================================================================================\n",
       "Total params: 1,824\n",
       "Trainable params: 1,824\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.38\n",
       "==========================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 226.49\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 232.79\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(encoder_block, (1, 2, 48, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38118634-15c8-4d07-82ac-d493818750d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_block = SimpleBlock(32, 3, 3, 0.1, True, False, dimensions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524de286-2738-4b74-8380-62e520872ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleBlock                              --                        --\n",
       "├─ConvTranspose3d: 1-1                   [8, 3, 24, 128, 128]      2,595\n",
       "├─BatchNorm3d: 1-2                       [8, 3, 24, 128, 128]      6\n",
       "├─Dropout3d: 1-3                         [8, 3, 24, 128, 128]      --\n",
       "==========================================================================================\n",
       "Total params: 2,601\n",
       "Trainable params: 2,601\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.16\n",
       "==========================================================================================\n",
       "Input size (MB): 50.33\n",
       "Forward/backward pass size (MB): 150.99\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 201.34\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(decoder_block, (8, 32, 12, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd343f7d-72f0-472d-bbdd-5903271d51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = FullyConvolutionalAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d861a96-60e6-4767-a54d-edf0918e48e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FullyConvolutionalAutoEncoder            --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─SimpleBlock: 2-1                  [4, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-1                  [4, 64, 128, 128]         1,792\n",
       "│    │    └─BatchNorm2d: 3-2             [4, 64, 64, 64]           128\n",
       "│    │    └─Dropout2d: 3-3               [4, 64, 64, 64]           --\n",
       "│    └─SimpleBlock: 2-2                  [4, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-4                  [4, 128, 64, 64]          73,856\n",
       "│    │    └─BatchNorm2d: 3-5             [4, 128, 32, 32]          256\n",
       "│    │    └─Dropout2d: 3-6               [4, 128, 32, 32]          --\n",
       "│    └─SimpleBlock: 2-3                  [4, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-7                  [4, 256, 32, 32]          295,168\n",
       "│    │    └─BatchNorm2d: 3-8             [4, 256, 16, 16]          512\n",
       "│    │    └─Dropout2d: 3-9               [4, 256, 16, 16]          --\n",
       "│    └─SimpleBlock: 2-4                  [4, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-10                 [4, 512, 16, 16]          1,180,160\n",
       "│    │    └─BatchNorm2d: 3-11            [4, 512, 8, 8]            1,024\n",
       "│    │    └─Dropout2d: 3-12              [4, 512, 8, 8]            --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─SimpleBlock: 2-5                  [4, 512, 16, 16]          --\n",
       "│    │    └─ConvTranspose2d: 3-13        [4, 512, 16, 16]          2,359,808\n",
       "│    │    └─BatchNorm2d: 3-14            [4, 512, 16, 16]          1,024\n",
       "│    │    └─Dropout2d: 3-15              [4, 512, 16, 16]          --\n",
       "│    └─SimpleBlock: 2-6                  [4, 256, 32, 32]          --\n",
       "│    │    └─ConvTranspose2d: 3-16        [4, 256, 32, 32]          1,179,904\n",
       "│    │    └─BatchNorm2d: 3-17            [4, 256, 32, 32]          512\n",
       "│    │    └─Dropout2d: 3-18              [4, 256, 32, 32]          --\n",
       "│    └─SimpleBlock: 2-7                  [4, 128, 64, 64]          --\n",
       "│    │    └─ConvTranspose2d: 3-19        [4, 128, 64, 64]          295,040\n",
       "│    │    └─BatchNorm2d: 3-20            [4, 128, 64, 64]          256\n",
       "│    │    └─Dropout2d: 3-21              [4, 128, 64, 64]          --\n",
       "│    └─SimpleBlock: 2-8                  [4, 64, 128, 128]         --\n",
       "│    │    └─ConvTranspose2d: 3-22        [4, 64, 128, 128]         73,792\n",
       "│    │    └─BatchNorm2d: 3-23            [4, 64, 128, 128]         128\n",
       "│    │    └─Dropout2d: 3-24              [4, 64, 128, 128]         --\n",
       "│    └─SimpleBlock: 2-9                  [4, 1, 256, 256]          --\n",
       "│    │    └─ConvTranspose2d: 3-25        [4, 1, 256, 256]          577\n",
       "│    │    └─BatchNorm2d: 3-26            [4, 1, 256, 256]          2\n",
       "│    │    └─Dropout2d: 3-27              [4, 1, 256, 256]          --\n",
       "├─Softmax: 1-3                           [4, 1, 256, 256]          --\n",
       "==========================================================================================\n",
       "Total params: 5,463,939\n",
       "Trainable params: 5,463,939\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 20.82\n",
       "==========================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 208.67\n",
       "Params size (MB): 21.86\n",
       "Estimated Total Size (MB): 231.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(ae, (4, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64de33ff-6d8f-4ff6-99f5-4b2113fe0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestKiUNet3D(nn.Module):\n",
    "    # I have slightly adapted this to use transpose convolution layers as opposed to interpolation...\n",
    "    # not sure if that is the best idea or not\n",
    "    # the standard version (class below, uses interpolation like they do)\n",
    "    def __init__(self, encoder_layers=[16,32,64], decoder_layers=[32,16,8], \n",
    "                 encoderf1_layers=[16,32,64], decoderf1_layers=[32,16,8], \n",
    "                 intere_layers=[16,32,64], interd_layers=[32,16],\n",
    "                 in_channels=3, out_channels=1, kernel_size=3, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout_p = dropout_p\n",
    "        dimensions = 3\n",
    "        \n",
    "        \n",
    "        self.encoder_blocks = block_list([in_channels] + encoder_layers[:-1], encoder_layers,\n",
    "                                        kernel_size, dropout_p, False, max_pooling=True, dimensions=dimensions)\n",
    "        \n",
    "        self.decoder_blocks = block_list([encoder_layers[-1]] + decoder_layers[:-1], decoder_layers,\n",
    "                                        kernel_size, dropout_p, False, max_pooling=False, dimensions=dimensions)\n",
    "        \n",
    "        self.encoderf1_blocks = block_list([in_channels] + encoderf1_layers[:-1], encoderf1_layers,\n",
    "                                          kernel_size, dropout_p, False, max_pooling=False, dimensions=dimensions)\n",
    "        \n",
    "        self.decoderf1_blocks = block_list([encoderf1_layers[-1]] + decoderf1_layers[:-1], decoderf1_layers,\n",
    "                                          kernel_size, dropout_p, False, max_pooling=True, dimensions=dimensions)\n",
    "        \n",
    "        self.intere1_blocks = block_list(intere_layers, intere_layers, \n",
    "                                         kernel_size, dropout_p, False, max_pooling=False, dimensions=dimensions)\n",
    "        \n",
    "        self.intere2_blocks = block_list(intere_layers, intere_layers, \n",
    "                                         kernel_size, dropout_p, False, max_pooling=False, dimensions=dimensions)\n",
    "        \n",
    "        self.interd1_blocks = block_list(interd_layers, interd_layers, \n",
    "                                         kernel_size, dropout_p, False, max_pooling=False, dimensions=dimensions)\n",
    "        \n",
    "        self.interd2_blocks = block_list(interd_layers, interd_layers,\n",
    "                                        kernel_size, dropout_p, False, max_pooling=False, dimensions=dimensions)\n",
    "        \n",
    "        self.final_conv = nn.Conv3d(8, out_channels=out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "        mode = 'trilinear'\n",
    "        self.upscale_ki = lambda x : F.interpolate(x, scale_factor=(1,2,2), mode=mode)\n",
    "        self.upscale_u = lambda x : F.interpolate(x, scale_factor=2, mode=mode)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        unet_out = x\n",
    "        kinet_out = x\n",
    "        skip_conns_stack = []\n",
    "        scale_factor = 1\n",
    "        mode = 'trilinear'\n",
    "        \n",
    "        # encoder path\n",
    "        num_blocks = len(self.encoder_blocks)\n",
    "        for l in range(num_blocks):\n",
    "            # standard forward pass for both paths\n",
    "            unet_out = self.encoder_blocks[l](unet_out)\n",
    "            kinet_out = self.upscale_ki(self.encoderf1_blocks[l](kinet_out))\n",
    "            \n",
    "            print(\"unet out shape: \", unet_out.shape)\n",
    "            print(\"kinet out shape: \", kinet_out.shape)\n",
    "            \n",
    "            tmp = unet_out\n",
    "            \n",
    "            # CRFB block\n",
    "            scale_factor *= 4.\n",
    "            crfb1 = self.intere1_blocks[l](kinet_out)\n",
    "            print(\"crbf unet out shape: \", crfb1.shape)\n",
    "            unet_out = torch.add(\n",
    "                unet_out,\n",
    "                F.interpolate(crfb1, size=unet_out.size()[2:], scale_factor=None, mode=mode)\n",
    "            )\n",
    "            print(\"crbf add unet out shape: \", unet_out.shape)\n",
    "            \n",
    "            crfb2 = self.intere2_blocks[l](tmp)\n",
    "            print(\"crbf kinet out shape: \", crfb2.shape)\n",
    "            print(kinet_out.size())\n",
    "            interpolated = F.interpolate(crfb2, size=kinet_out.size()[2:],scale_factor=None,mode=mode)\n",
    "            print(\"interpolated shape: \", interpolated.shape)\n",
    "            kinet_out = torch.add(\n",
    "                kinet_out,\n",
    "                interpolated\n",
    "            )\n",
    "            print(\"crbf add kinet out shape: \", kinet_out.shape)\n",
    "            print()\n",
    "            \n",
    "            # append skip connections\n",
    "            if l != num_blocks - 1:\n",
    "                skip_conns_stack.append((unet_out, kinet_out))\n",
    "            # print()\n",
    "            \n",
    "        print(\"decoder\\n\")\n",
    "            \n",
    "        # decoder path\n",
    "        for l in range(len(self.decoder_blocks)):\n",
    "            # standard forward pass for both paths\n",
    "            unet_out = self.upscale_u(self.decoder_blocks[l](unet_out))\n",
    "            kinet_out = self.decoderf1_blocks[l](kinet_out)\n",
    "            \n",
    "            print(\"unet out shape: \", unet_out.shape)\n",
    "            print(\"kinet out shape: \", kinet_out.shape)\n",
    "            \n",
    "            tmp = unet_out\n",
    "            \n",
    "            # CRFB block\n",
    "            if l != num_blocks - 1:\n",
    "                scale_factor /= 4.\n",
    "                crfb1 = self.interd1_blocks[l](kinet_out)\n",
    "                print(\"crbf unet out shape: \", crfb1.shape)\n",
    "                unet_out = torch.add(\n",
    "                    unet_out,\n",
    "                    F.interpolate(crfb1, size=unet_out.size()[2:], scale_factor=None, mode=mode)\n",
    "                )\n",
    "                print(\"crbf add unet out shape: \", unet_out.shape)\n",
    "\n",
    "                crfb2 =self.interd2_blocks[l](tmp)\n",
    "                print(\"crbf kinet out shape: \", crfb2.shape)\n",
    "                print(kinet_out.size())\n",
    "                interpolated = F.interpolate(crfb2, size=kinet_out.size()[2:], scale_factor=None, mode=mode)\n",
    "                print(\"interpolated shape: \", interpolated.shape)\n",
    "                kinet_out = torch.add(\n",
    "                    kinet_out,\n",
    "                    interpolated\n",
    "                )\n",
    "                print(\"crbf add kinet out shape: \", kinet_out.shape)\n",
    "            print()\n",
    "            \n",
    "            # add skip connections\n",
    "            if l != num_blocks - 1:\n",
    "                unet_skipc, kinet_skipc = skip_conns_stack.pop() # pop implements LIFO stack behaviour\n",
    "                print(\"skip size unet: \", unet_skipc.shape)\n",
    "                print(\"skip size kinet: \", kinet_skipc.shape)\n",
    "                print(\"unet size \", unet_out.shape)\n",
    "                print(\"kinet size\", kinet_out.shape)\n",
    "                # do padding where the sizes don't match\n",
    "                if unet_out.shape != unet_skipc.shape:\n",
    "                    # print(\"using\")\n",
    "                    unet_out = pad_3D_tensors(unet_out, unet_skipc.shape)\n",
    "                    # print(\"new unet shape: \", unet_out.shape)\n",
    "                if kinet_out.shape != kinet_skipc.shape:\n",
    "                    kinet_out = pad_3D_tensors(kinet_out, kinet_skipc.shape)\n",
    "                unet_out = torch.add(unet_out, unet_skipc)\n",
    "                kinet_out = torch.add(kinet_out, kinet_skipc)\n",
    "            \n",
    "        \n",
    "        # fusion of both branches\n",
    "        kinet_out = F.interpolate(kinet_out, scale_factor=(2,1,1), mode='trilinear')\n",
    "        print(\"out_shapes: \", unet_out.shape, kinet_out.shape)\n",
    "        if kinet_out.shape != unet_out.shape:\n",
    "            unet_out = pad_3D_tensors(unet_out, kinet_out.shape)\n",
    "        out = torch.add(unet_out, kinet_out)\n",
    "        out = self.final_conv(out)\n",
    "        out = self.soft(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n",
    "def pad_3D_tensors(img, target_shape):\n",
    "    img_shape = img.shape\n",
    "    lr_diff = target_shape[-3] - img_shape[-3]\n",
    "    top_bottom_diff = target_shape[-2] - img_shape[-2]\n",
    "    front_back_diff = target_shape[-1] - img_shape[-1]\n",
    "    l_pad = lr_diff // 2\n",
    "    r_pad = lr_diff - l_pad\n",
    "    top_pad = top_bottom_diff // 2\n",
    "    bottom_pad = top_bottom_diff - top_pad\n",
    "    front_pad = front_back_diff // 2\n",
    "    back_pad = front_back_diff - front_pad\n",
    "    \n",
    "    #print((l_pad, r_pad, top_pad, bottom_pad, front_pad, back_pad))\n",
    "    \n",
    "    return F.pad(img, (front_pad, back_pad, top_pad, bottom_pad, l_pad, r_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "191ee466-7aff-4b9a-b7b5-6edca494d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiunet = TestKiUNet3D(in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78277639-f7f5-4f9d-ad27-42e9fbcb8b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet out shape:  torch.Size([1, 16, 4, 7, 7])\n",
      "kinet out shape:  torch.Size([1, 16, 8, 30, 30])\n",
      "crbf unet out shape:  torch.Size([1, 16, 8, 30, 30])\n",
      "crbf add unet out shape:  torch.Size([1, 16, 4, 7, 7])\n",
      "crbf kinet out shape:  torch.Size([1, 16, 4, 7, 7])\n",
      "torch.Size([1, 16, 8, 30, 30])\n",
      "interpolated shape:  torch.Size([1, 16, 8, 30, 30])\n",
      "crbf add kinet out shape:  torch.Size([1, 16, 8, 30, 30])\n",
      "\n",
      "unet out shape:  torch.Size([1, 32, 2, 3, 3])\n",
      "kinet out shape:  torch.Size([1, 32, 8, 60, 60])\n",
      "crbf unet out shape:  torch.Size([1, 32, 8, 60, 60])\n",
      "crbf add unet out shape:  torch.Size([1, 32, 2, 3, 3])\n",
      "crbf kinet out shape:  torch.Size([1, 32, 2, 3, 3])\n",
      "torch.Size([1, 32, 8, 60, 60])\n",
      "interpolated shape:  torch.Size([1, 32, 8, 60, 60])\n",
      "crbf add kinet out shape:  torch.Size([1, 32, 8, 60, 60])\n",
      "\n",
      "unet out shape:  torch.Size([1, 64, 1, 1, 1])\n",
      "kinet out shape:  torch.Size([1, 64, 8, 120, 120])\n",
      "crbf unet out shape:  torch.Size([1, 64, 8, 120, 120])\n",
      "crbf add unet out shape:  torch.Size([1, 64, 1, 1, 1])\n",
      "crbf kinet out shape:  torch.Size([1, 64, 1, 1, 1])\n",
      "torch.Size([1, 64, 8, 120, 120])\n",
      "interpolated shape:  torch.Size([1, 64, 8, 120, 120])\n",
      "crbf add kinet out shape:  torch.Size([1, 64, 8, 120, 120])\n",
      "\n",
      "decoder\n",
      "\n",
      "unet out shape:  torch.Size([1, 32, 2, 2, 2])\n",
      "kinet out shape:  torch.Size([1, 32, 4, 60, 60])\n",
      "crbf unet out shape:  torch.Size([1, 32, 4, 60, 60])\n",
      "crbf add unet out shape:  torch.Size([1, 32, 2, 2, 2])\n",
      "crbf kinet out shape:  torch.Size([1, 32, 2, 2, 2])\n",
      "torch.Size([1, 32, 4, 60, 60])\n",
      "interpolated shape:  torch.Size([1, 32, 4, 60, 60])\n",
      "crbf add kinet out shape:  torch.Size([1, 32, 4, 60, 60])\n",
      "\n",
      "skip size unet:  torch.Size([1, 32, 2, 3, 3])\n",
      "skip size kinet:  torch.Size([1, 32, 8, 60, 60])\n",
      "unet size  torch.Size([1, 32, 2, 2, 2])\n",
      "kinet size torch.Size([1, 32, 4, 60, 60])\n",
      "unet out shape:  torch.Size([1, 16, 4, 6, 6])\n",
      "kinet out shape:  torch.Size([1, 16, 4, 30, 30])\n",
      "crbf unet out shape:  torch.Size([1, 16, 4, 30, 30])\n",
      "crbf add unet out shape:  torch.Size([1, 16, 4, 6, 6])\n",
      "crbf kinet out shape:  torch.Size([1, 16, 4, 6, 6])\n",
      "torch.Size([1, 16, 4, 30, 30])\n",
      "interpolated shape:  torch.Size([1, 16, 4, 30, 30])\n",
      "crbf add kinet out shape:  torch.Size([1, 16, 4, 30, 30])\n",
      "\n",
      "skip size unet:  torch.Size([1, 16, 4, 7, 7])\n",
      "skip size kinet:  torch.Size([1, 16, 8, 30, 30])\n",
      "unet size  torch.Size([1, 16, 4, 6, 6])\n",
      "kinet size torch.Size([1, 16, 4, 30, 30])\n",
      "unet out shape:  torch.Size([1, 8, 8, 14, 14])\n",
      "kinet out shape:  torch.Size([1, 8, 4, 15, 15])\n",
      "\n",
      "out_shapes:  torch.Size([1, 8, 8, 14, 14]) torch.Size([1, 8, 8, 15, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TestKiUNet3D                             --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "├─ModuleList: 1-7                        --                        --\n",
       "├─ModuleList: 1-8                        --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─SimpleBlock: 2-1                  [1, 16, 4, 7, 7]          --\n",
       "│    │    └─Conv3d: 3-1                  [1, 16, 8, 15, 15]        448\n",
       "│    │    └─BatchNorm3d: 3-2             [1, 16, 4, 7, 7]          32\n",
       "│    │    └─Dropout3d: 3-3               [1, 16, 4, 7, 7]          --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─SimpleBlock: 2-2                  [1, 16, 8, 15, 15]        --\n",
       "│    │    └─Conv3d: 3-4                  [1, 16, 8, 15, 15]        448\n",
       "│    │    └─BatchNorm3d: 3-5             [1, 16, 8, 15, 15]        32\n",
       "│    │    └─Dropout3d: 3-6               [1, 16, 8, 15, 15]        --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "│    └─SimpleBlock: 2-3                  [1, 16, 8, 30, 30]        --\n",
       "│    │    └─Conv3d: 3-7                  [1, 16, 8, 30, 30]        6,928\n",
       "│    │    └─BatchNorm3d: 3-8             [1, 16, 8, 30, 30]        32\n",
       "│    │    └─Dropout3d: 3-9               [1, 16, 8, 30, 30]        --\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "│    └─SimpleBlock: 2-4                  [1, 16, 4, 7, 7]          --\n",
       "│    │    └─Conv3d: 3-10                 [1, 16, 4, 7, 7]          6,928\n",
       "│    │    └─BatchNorm3d: 3-11            [1, 16, 4, 7, 7]          32\n",
       "│    │    └─Dropout3d: 3-12              [1, 16, 4, 7, 7]          --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─SimpleBlock: 2-5                  [1, 32, 2, 3, 3]          --\n",
       "│    │    └─Conv3d: 3-13                 [1, 32, 4, 7, 7]          13,856\n",
       "│    │    └─BatchNorm3d: 3-14            [1, 32, 2, 3, 3]          64\n",
       "│    │    └─Dropout3d: 3-15              [1, 32, 2, 3, 3]          --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─SimpleBlock: 2-6                  [1, 32, 8, 30, 30]        --\n",
       "│    │    └─Conv3d: 3-16                 [1, 32, 8, 30, 30]        13,856\n",
       "│    │    └─BatchNorm3d: 3-17            [1, 32, 8, 30, 30]        64\n",
       "│    │    └─Dropout3d: 3-18              [1, 32, 8, 30, 30]        --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "│    └─SimpleBlock: 2-7                  [1, 32, 8, 60, 60]        --\n",
       "│    │    └─Conv3d: 3-19                 [1, 32, 8, 60, 60]        27,680\n",
       "│    │    └─BatchNorm3d: 3-20            [1, 32, 8, 60, 60]        64\n",
       "│    │    └─Dropout3d: 3-21              [1, 32, 8, 60, 60]        --\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "│    └─SimpleBlock: 2-8                  [1, 32, 2, 3, 3]          --\n",
       "│    │    └─Conv3d: 3-22                 [1, 32, 2, 3, 3]          27,680\n",
       "│    │    └─BatchNorm3d: 3-23            [1, 32, 2, 3, 3]          64\n",
       "│    │    └─Dropout3d: 3-24              [1, 32, 2, 3, 3]          --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─SimpleBlock: 2-9                  [1, 64, 1, 1, 1]          --\n",
       "│    │    └─Conv3d: 3-25                 [1, 64, 2, 3, 3]          55,360\n",
       "│    │    └─BatchNorm3d: 3-26            [1, 64, 1, 1, 1]          128\n",
       "│    │    └─Dropout3d: 3-27              [1, 64, 1, 1, 1]          --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─SimpleBlock: 2-10                 [1, 64, 8, 60, 60]        --\n",
       "│    │    └─Conv3d: 3-28                 [1, 64, 8, 60, 60]        55,360\n",
       "│    │    └─BatchNorm3d: 3-29            [1, 64, 8, 60, 60]        128\n",
       "│    │    └─Dropout3d: 3-30              [1, 64, 8, 60, 60]        --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "│    └─SimpleBlock: 2-11                 [1, 64, 8, 120, 120]      --\n",
       "│    │    └─Conv3d: 3-31                 [1, 64, 8, 120, 120]      110,656\n",
       "│    │    └─BatchNorm3d: 3-32            [1, 64, 8, 120, 120]      128\n",
       "│    │    └─Dropout3d: 3-33              [1, 64, 8, 120, 120]      --\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "│    └─SimpleBlock: 2-12                 [1, 64, 1, 1, 1]          --\n",
       "│    │    └─Conv3d: 3-34                 [1, 64, 1, 1, 1]          110,656\n",
       "│    │    └─BatchNorm3d: 3-35            [1, 64, 1, 1, 1]          128\n",
       "│    │    └─Dropout3d: 3-36              [1, 64, 1, 1, 1]          --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─SimpleBlock: 2-13                 [1, 32, 1, 1, 1]          --\n",
       "│    │    └─Conv3d: 3-37                 [1, 32, 1, 1, 1]          55,328\n",
       "│    │    └─BatchNorm3d: 3-38            [1, 32, 1, 1, 1]          64\n",
       "│    │    └─Dropout3d: 3-39              [1, 32, 1, 1, 1]          --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─SimpleBlock: 2-14                 [1, 32, 4, 60, 60]        --\n",
       "│    │    └─Conv3d: 3-40                 [1, 32, 8, 120, 120]      55,328\n",
       "│    │    └─BatchNorm3d: 3-41            [1, 32, 4, 60, 60]        64\n",
       "│    │    └─Dropout3d: 3-42              [1, 32, 4, 60, 60]        --\n",
       "├─ModuleList: 1-7                        --                        --\n",
       "│    └─SimpleBlock: 2-15                 [1, 32, 4, 60, 60]        --\n",
       "│    │    └─Conv3d: 3-43                 [1, 32, 4, 60, 60]        27,680\n",
       "│    │    └─BatchNorm3d: 3-44            [1, 32, 4, 60, 60]        64\n",
       "│    │    └─Dropout3d: 3-45              [1, 32, 4, 60, 60]        --\n",
       "├─ModuleList: 1-8                        --                        --\n",
       "│    └─SimpleBlock: 2-16                 [1, 32, 2, 2, 2]          --\n",
       "│    │    └─Conv3d: 3-46                 [1, 32, 2, 2, 2]          27,680\n",
       "│    │    └─BatchNorm3d: 3-47            [1, 32, 2, 2, 2]          64\n",
       "│    │    └─Dropout3d: 3-48              [1, 32, 2, 2, 2]          --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─SimpleBlock: 2-17                 [1, 16, 2, 3, 3]          --\n",
       "│    │    └─Conv3d: 3-49                 [1, 16, 2, 3, 3]          13,840\n",
       "│    │    └─BatchNorm3d: 3-50            [1, 16, 2, 3, 3]          32\n",
       "│    │    └─Dropout3d: 3-51              [1, 16, 2, 3, 3]          --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─SimpleBlock: 2-18                 [1, 16, 4, 30, 30]        --\n",
       "│    │    └─Conv3d: 3-52                 [1, 16, 8, 60, 60]        13,840\n",
       "│    │    └─BatchNorm3d: 3-53            [1, 16, 4, 30, 30]        32\n",
       "│    │    └─Dropout3d: 3-54              [1, 16, 4, 30, 30]        --\n",
       "├─ModuleList: 1-7                        --                        --\n",
       "│    └─SimpleBlock: 2-19                 [1, 16, 4, 30, 30]        --\n",
       "│    │    └─Conv3d: 3-55                 [1, 16, 4, 30, 30]        6,928\n",
       "│    │    └─BatchNorm3d: 3-56            [1, 16, 4, 30, 30]        32\n",
       "│    │    └─Dropout3d: 3-57              [1, 16, 4, 30, 30]        --\n",
       "├─ModuleList: 1-8                        --                        --\n",
       "│    └─SimpleBlock: 2-20                 [1, 16, 4, 6, 6]          --\n",
       "│    │    └─Conv3d: 3-58                 [1, 16, 4, 6, 6]          6,928\n",
       "│    │    └─BatchNorm3d: 3-59            [1, 16, 4, 6, 6]          32\n",
       "│    │    └─Dropout3d: 3-60              [1, 16, 4, 6, 6]          --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─SimpleBlock: 2-21                 [1, 8, 4, 7, 7]           --\n",
       "│    │    └─Conv3d: 3-61                 [1, 8, 4, 7, 7]           3,464\n",
       "│    │    └─BatchNorm3d: 3-62            [1, 8, 4, 7, 7]           16\n",
       "│    │    └─Dropout3d: 3-63              [1, 8, 4, 7, 7]           --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─SimpleBlock: 2-22                 [1, 8, 4, 15, 15]         --\n",
       "│    │    └─Conv3d: 3-64                 [1, 8, 8, 30, 30]         3,464\n",
       "│    │    └─BatchNorm3d: 3-65            [1, 8, 4, 15, 15]         16\n",
       "│    │    └─Dropout3d: 3-66              [1, 8, 4, 15, 15]         --\n",
       "├─Conv3d: 1-9                            [1, 1, 8, 15, 15]         9\n",
       "├─Softmax: 1-10                          [1, 1, 8, 15, 15]         --\n",
       "==========================================================================================\n",
       "Total params: 645,657\n",
       "Trainable params: 645,657\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 22.52\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 214.80\n",
       "Params size (MB): 2.58\n",
       "Estimated Total Size (MB): 217.39\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(kiunet, (1, 1, 8, 15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184cbad2-66ab-453d-8e52-7b52aa46325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1, 1, 17, 15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa095a90-a839-4509-931e-e19e5d21f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = kiunet(x.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca52a99-1090-4297-b2cc-b2583b33b8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 15, 15])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "69996e9b-b62e-4d44-9e1a-3dd3ddb1e3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f13d6588ee0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.numpy()[0, 0, 5, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e7134e5c-c121-4652-9fe7-dffa5dda73b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f13d41d0d90>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y.detach().cpu().numpy()[0, 0, 5, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5665f3b-d558-4589-9d04-4abe334b16a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestKiUNetMod1(nn.Module):\n",
    "    # copy their KiUnet and then move on to other baseline models, \n",
    "    # and try to get a model from one of the papers with code top models.\n",
    "    \n",
    "    def __init__(self, encoder_layers=[16,32,64], decoder_layers=[32,16,8], \n",
    "                 encoderf1_layers=[16,32,64], decoderf1_layers=[32,16,8], \n",
    "                 intere_layers=[16,32,64], interd_layers=[32,16],\n",
    "                         in_channels=3, out_channels=1, kernel_size=3, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_blocks = nn.ModuleList([\n",
    "            SimpleBlock(ins, outs, kernel_size, dropout_p, False, max_pooling=True)\n",
    "            for (ins, outs) in\n",
    "            zip ([in_channels] + encoder_layers[:-1], encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            SimpleBlock(ins, outs, kernel_size, dropout_p, True, max_pooling=False)\n",
    "            for (ins, outs) in \n",
    "            zip([encoder_layers[-1]] + decoder_layers[:-1], decoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.encoderf1_blocks = nn.ModuleList([\n",
    "            SimpleBlock(ins, outs, kernel_size, dropout_p, True, max_pooling=False)\n",
    "            for (ins, outs) in\n",
    "            zip ([in_channels] + encoderf1_layers[:-1], encoderf1_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoderf1_blocks = nn.ModuleList([\n",
    "            SimpleBlock(ins, outs, kernel_size, dropout_p, False, max_pooling=True)\n",
    "            for (ins, outs) in \n",
    "            zip([encoderf1_layers[-1]] + decoderf1_layers[:-1], decoderf1_layers)\n",
    "        ])\n",
    "        \n",
    "        self.intere1_blocks = nn.ModuleList([\n",
    "            SimpleBlock(ins, outs, kernel_size, dropout_p, False, max_pooling=False)\n",
    "            for (ins, outs) in\n",
    "            zip (intere_layers, intere_layers)\n",
    "        ])\n",
    "        \n",
    "        self.intere2_blocks = nn.ModuleList([\n",
    "            SimpleBlock(ins, outs, kernel_size, dropout_p, False, max_pooling=False)\n",
    "            for (ins, outs) in\n",
    "            zip (intere_layers, intere_layers)\n",
    "        ])\n",
    "        \n",
    "        self.interd1_blocks = nn.ModuleList([\n",
    "            SimpleBlock(ins, outs, kernel_size, dropout_p, False, max_pooling=False)\n",
    "            for (ins, outs) in\n",
    "            zip (interd_layers, interd_layers)\n",
    "        ])\n",
    "        \n",
    "        self.interd2_blocks = nn.ModuleList([\n",
    "            SimpleBlock(ins, outs, kernel_size, dropout_p, False, max_pooling=False)\n",
    "            for (ins, outs) in\n",
    "            zip (interd_layers, interd_layers)\n",
    "        ])\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(8, out_channels=2, kernel_size=1, stride=1, padding=0)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        unet_out = x\n",
    "        kinet_out = x\n",
    "        skip_conns_stack = []\n",
    "        scale_factor = 1\n",
    "        \n",
    "        # print(\"0\")\n",
    "        # print(\"unet out shape:  \", unet_out.shape)\n",
    "        # print(\"kinet out shape: \", kinet_out.shape)\n",
    "        # print(\"------------------\\n\")\n",
    "        \n",
    "        \n",
    "        # encoder path\n",
    "        num_blocks = len(self.encoder_blocks)\n",
    "        for l in range(num_blocks):\n",
    "            # standard forward pass for both paths\n",
    "            unet_out = self.encoder_blocks[l](unet_out)\n",
    "            kinet_out = self.encoderf1_blocks[l](kinet_out)\n",
    "            \n",
    "            tmp = unet_out\n",
    "            \n",
    "            # print(l+1)\n",
    "            # print(\"unet out shape:  \", unet_out.shape)\n",
    "            # print(\"kinet out shape: \", kinet_out.shape)\n",
    "            # print(\"------------------\\n\")\n",
    "            \n",
    "            # CRFB block\n",
    "            scale_factor *= 4.\n",
    "            crfb1 = self.intere1_blocks[l](kinet_out)\n",
    "            # print(\"crfb1 shape: \", crfb1.shape)\n",
    "            unet_out = torch.add(\n",
    "                unet_out,\n",
    "                F.interpolate(crfb1, scale_factor=1./scale_factor, mode='bilinear')\n",
    "            )\n",
    "            # print(\"post crfb unet out shape:  \", unet_out.shape)\n",
    "            \n",
    "            crfb2 = self.intere2_blocks[l](tmp)\n",
    "            # print(\"crfb2 shape: \", crfb2.shape)\n",
    "            kinet_out = torch.add(\n",
    "                kinet_out,\n",
    "                F.interpolate(crfb2, scale_factor=scale_factor,mode='bilinear')\n",
    "            )\n",
    "            # print(\"post crfb kinet out shape: \", kinet_out.shape)\n",
    "            \n",
    "            # append skip connections\n",
    "            if l != num_blocks - 1:\n",
    "                skip_conns_stack.append((unet_out, kinet_out))\n",
    "            \n",
    "            \n",
    "        # print(\"\\nstack shapes:   \")\n",
    "        # for pair in skip_conns_stack:\n",
    "        #     print(pair[0].shape, pair[1].shape)\n",
    "        # print(\"\\n\")\n",
    "            \n",
    "            \n",
    "        # decoder path\n",
    "        # print(\"--------------\")\n",
    "        # print(\"decoder path: \")\n",
    "        for l in range(len(self.decoder_blocks)):\n",
    "            # standard forward pass for both paths\n",
    "            unet_out = self.decoder_blocks[l](unet_out)\n",
    "            kinet_out = self.decoderf1_blocks[l](kinet_out)\n",
    "            \n",
    "            # print(l+1)\n",
    "            # print(\"unet out shape:  \", unet_out.shape)\n",
    "            # print(\"kinet out shape: \", kinet_out.shape)\n",
    "            # print(\"------------------\\n\")\n",
    "            \n",
    "            tmp = unet_out\n",
    "            \n",
    "            # CRFB block\n",
    "            if l != num_blocks - 1:\n",
    "                scale_factor /= 4.\n",
    "                crfb1 = self.interd1_blocks[l](kinet_out)\n",
    "                # print(\"crfb1 shape: \", crfb1.shape)\n",
    "                unet_out = torch.add(\n",
    "                    unet_out,\n",
    "                    F.interpolate(crfb1, scale_factor=1./scale_factor, mode='bilinear')\n",
    "                )\n",
    "                # print(\"post crfb unet out shape:  \", unet_out.shape)\n",
    "\n",
    "                crfb2 =self.interd2_blocks[l](tmp)\n",
    "                # print(\"crfb2 shape: \", crfb1.shape)\n",
    "                kinet_out = torch.add(\n",
    "                    kinet_out,\n",
    "                    F.interpolate(crfb2, scale_factor=scale_factor, mode='bilinear')\n",
    "                )\n",
    "                # print(\"post crfb kinet out shape: \", kinet_out.shape)\n",
    "            \n",
    "            # add skip connections\n",
    "            if l != num_blocks - 1:\n",
    "                unet_skipc, kinet_skipc = skip_conns_stack.pop() # pop implements LIFO stack behaviour\n",
    "                # print(\"skip unet shape:  \", unet_skipc.shape)\n",
    "                # print(\"skip kinet shape: \", kinet_skipc.shape)\n",
    "                unet_out = torch.add(unet_out, unet_skipc)\n",
    "                kinet_out = torch.add(kinet_out, kinet_skipc)\n",
    "            \n",
    "            \n",
    "            \n",
    "        # fusion of both branches\n",
    "        out = torch.add(unet_out, kinet_out)\n",
    "        out = self.final_conv(out)\n",
    "        out = self.soft(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0541c717-04a9-4930-8c03-0091b0ae44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiunet = TestKiUNetMod1(in_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "19a5cbc0-e093-4960-8cf2-13c4a2cc997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(kiunet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29908df3-e9be-43b7-bf6c-0cf555fc1595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TestKiUNetMod1                           --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "├─ModuleList: 1-7                        --                        --\n",
       "├─ModuleList: 1-8                        --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─SimpleBlock: 2-1                  [1, 16, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 16, 64, 64]           160\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 16, 32, 32]           32\n",
       "│    │    └─Dropout2d: 3-3               [1, 16, 32, 32]           --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─SimpleBlock: 2-2                  [1, 16, 128, 128]         --\n",
       "│    │    └─ConvTranspose2d: 3-4         [1, 16, 128, 128]         160\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 16, 128, 128]         32\n",
       "│    │    └─Dropout2d: 3-6               [1, 16, 128, 128]         --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "│    └─SimpleBlock: 2-3                  [1, 16, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-7                  [1, 16, 128, 128]         2,320\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 16, 128, 128]         32\n",
       "│    │    └─Dropout2d: 3-9               [1, 16, 128, 128]         --\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "│    └─SimpleBlock: 2-4                  [1, 16, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 16, 32, 32]           2,320\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 16, 32, 32]           32\n",
       "│    │    └─Dropout2d: 3-12              [1, 16, 32, 32]           --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─SimpleBlock: 2-5                  [1, 32, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-13                 [1, 32, 32, 32]           4,640\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 32, 16, 16]           64\n",
       "│    │    └─Dropout2d: 3-15              [1, 32, 16, 16]           --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─SimpleBlock: 2-6                  [1, 32, 256, 256]         --\n",
       "│    │    └─ConvTranspose2d: 3-16        [1, 32, 256, 256]         4,640\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 32, 256, 256]         64\n",
       "│    │    └─Dropout2d: 3-18              [1, 32, 256, 256]         --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "│    └─SimpleBlock: 2-7                  [1, 32, 256, 256]         --\n",
       "│    │    └─Conv2d: 3-19                 [1, 32, 256, 256]         9,248\n",
       "│    │    └─BatchNorm2d: 3-20            [1, 32, 256, 256]         64\n",
       "│    │    └─Dropout2d: 3-21              [1, 32, 256, 256]         --\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "│    └─SimpleBlock: 2-8                  [1, 32, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-22                 [1, 32, 16, 16]           9,248\n",
       "│    │    └─BatchNorm2d: 3-23            [1, 32, 16, 16]           64\n",
       "│    │    └─Dropout2d: 3-24              [1, 32, 16, 16]           --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─SimpleBlock: 2-9                  [1, 64, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-25                 [1, 64, 16, 16]           18,496\n",
       "│    │    └─BatchNorm2d: 3-26            [1, 64, 8, 8]             128\n",
       "│    │    └─Dropout2d: 3-27              [1, 64, 8, 8]             --\n",
       "├─ModuleList: 1-3                        --                        --\n",
       "│    └─SimpleBlock: 2-10                 [1, 64, 512, 512]         --\n",
       "│    │    └─ConvTranspose2d: 3-28        [1, 64, 512, 512]         18,496\n",
       "│    │    └─BatchNorm2d: 3-29            [1, 64, 512, 512]         128\n",
       "│    │    └─Dropout2d: 3-30              [1, 64, 512, 512]         --\n",
       "├─ModuleList: 1-5                        --                        --\n",
       "│    └─SimpleBlock: 2-11                 [1, 64, 512, 512]         --\n",
       "│    │    └─Conv2d: 3-31                 [1, 64, 512, 512]         36,928\n",
       "│    │    └─BatchNorm2d: 3-32            [1, 64, 512, 512]         128\n",
       "│    │    └─Dropout2d: 3-33              [1, 64, 512, 512]         --\n",
       "├─ModuleList: 1-6                        --                        --\n",
       "│    └─SimpleBlock: 2-12                 [1, 64, 8, 8]             --\n",
       "│    │    └─Conv2d: 3-34                 [1, 64, 8, 8]             36,928\n",
       "│    │    └─BatchNorm2d: 3-35            [1, 64, 8, 8]             128\n",
       "│    │    └─Dropout2d: 3-36              [1, 64, 8, 8]             --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─SimpleBlock: 2-13                 [1, 32, 16, 16]           --\n",
       "│    │    └─ConvTranspose2d: 3-37        [1, 32, 16, 16]           18,464\n",
       "│    │    └─BatchNorm2d: 3-38            [1, 32, 16, 16]           64\n",
       "│    │    └─Dropout2d: 3-39              [1, 32, 16, 16]           --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─SimpleBlock: 2-14                 [1, 32, 256, 256]         --\n",
       "│    │    └─Conv2d: 3-40                 [1, 32, 512, 512]         18,464\n",
       "│    │    └─BatchNorm2d: 3-41            [1, 32, 256, 256]         64\n",
       "│    │    └─Dropout2d: 3-42              [1, 32, 256, 256]         --\n",
       "├─ModuleList: 1-7                        --                        --\n",
       "│    └─SimpleBlock: 2-15                 [1, 32, 256, 256]         --\n",
       "│    │    └─Conv2d: 3-43                 [1, 32, 256, 256]         9,248\n",
       "│    │    └─BatchNorm2d: 3-44            [1, 32, 256, 256]         64\n",
       "│    │    └─Dropout2d: 3-45              [1, 32, 256, 256]         --\n",
       "├─ModuleList: 1-8                        --                        --\n",
       "│    └─SimpleBlock: 2-16                 [1, 32, 16, 16]           --\n",
       "│    │    └─Conv2d: 3-46                 [1, 32, 16, 16]           9,248\n",
       "│    │    └─BatchNorm2d: 3-47            [1, 32, 16, 16]           64\n",
       "│    │    └─Dropout2d: 3-48              [1, 32, 16, 16]           --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─SimpleBlock: 2-17                 [1, 16, 32, 32]           --\n",
       "│    │    └─ConvTranspose2d: 3-49        [1, 16, 32, 32]           4,624\n",
       "│    │    └─BatchNorm2d: 3-50            [1, 16, 32, 32]           32\n",
       "│    │    └─Dropout2d: 3-51              [1, 16, 32, 32]           --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─SimpleBlock: 2-18                 [1, 16, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-52                 [1, 16, 256, 256]         4,624\n",
       "│    │    └─BatchNorm2d: 3-53            [1, 16, 128, 128]         32\n",
       "│    │    └─Dropout2d: 3-54              [1, 16, 128, 128]         --\n",
       "├─ModuleList: 1-7                        --                        --\n",
       "│    └─SimpleBlock: 2-19                 [1, 16, 128, 128]         --\n",
       "│    │    └─Conv2d: 3-55                 [1, 16, 128, 128]         2,320\n",
       "│    │    └─BatchNorm2d: 3-56            [1, 16, 128, 128]         32\n",
       "│    │    └─Dropout2d: 3-57              [1, 16, 128, 128]         --\n",
       "├─ModuleList: 1-8                        --                        --\n",
       "│    └─SimpleBlock: 2-20                 [1, 16, 32, 32]           --\n",
       "│    │    └─Conv2d: 3-58                 [1, 16, 32, 32]           2,320\n",
       "│    │    └─BatchNorm2d: 3-59            [1, 16, 32, 32]           32\n",
       "│    │    └─Dropout2d: 3-60              [1, 16, 32, 32]           --\n",
       "├─ModuleList: 1-2                        --                        --\n",
       "│    └─SimpleBlock: 2-21                 [1, 8, 64, 64]            --\n",
       "│    │    └─ConvTranspose2d: 3-61        [1, 8, 64, 64]            1,160\n",
       "│    │    └─BatchNorm2d: 3-62            [1, 8, 64, 64]            16\n",
       "│    │    └─Dropout2d: 3-63              [1, 8, 64, 64]            --\n",
       "├─ModuleList: 1-4                        --                        --\n",
       "│    └─SimpleBlock: 2-22                 [1, 8, 64, 64]            --\n",
       "│    │    └─Conv2d: 3-64                 [1, 8, 128, 128]          1,160\n",
       "│    │    └─BatchNorm2d: 3-65            [1, 8, 64, 64]            16\n",
       "│    │    └─Dropout2d: 3-66              [1, 8, 64, 64]            --\n",
       "├─Conv2d: 1-9                            [1, 2, 64, 64]            18\n",
       "├─Softmax: 1-10                          [1, 2, 64, 64]            --\n",
       "==========================================================================================\n",
       "Total params: 216,546\n",
       "Trainable params: 216,546\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 21.32\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 748.78\n",
       "Params size (MB): 0.87\n",
       "Estimated Total Size (MB): 749.66\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(kiunet, (1, 1, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "377c5aba-c3d5-40b9-8cf4-f5736d8ef768",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,1,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b9cb412-9920-46ce-99fd-da30438b5919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "unet out shape:   torch.Size([1, 1, 64, 64])\n",
      "kinet out shape:  torch.Size([1, 1, 64, 64])\n",
      "------------------\n",
      "\n",
      "1\n",
      "unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "crfb1 shape:  torch.Size([1, 16, 128, 128])\n",
      "post crfb unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "crfb2 shape:  torch.Size([1, 16, 32, 32])\n",
      "post crfb kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "2\n",
      "unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "crfb1 shape:  torch.Size([1, 32, 256, 256])\n",
      "post crfb unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "crfb2 shape:  torch.Size([1, 32, 16, 16])\n",
      "post crfb kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "3\n",
      "unet out shape:   torch.Size([1, 64, 8, 8])\n",
      "kinet out shape:  torch.Size([1, 64, 512, 512])\n",
      "------------------\n",
      "\n",
      "crfb1 shape:  torch.Size([1, 64, 512, 512])\n",
      "post crfb unet out shape:   torch.Size([1, 64, 8, 8])\n",
      "crfb2 shape:  torch.Size([1, 64, 8, 8])\n",
      "post crfb kinet out shape:  torch.Size([1, 64, 512, 512])\n",
      "\n",
      "stack shapes:   \n",
      "torch.Size([1, 16, 32, 32]) torch.Size([1, 16, 128, 128])\n",
      "torch.Size([1, 32, 16, 16]) torch.Size([1, 32, 256, 256])\n",
      "\n",
      "\n",
      "--------------\n",
      "decoder path: \n",
      "1\n",
      "unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "------------------\n",
      "\n",
      "crfb1 shape:  torch.Size([1, 32, 256, 256])\n",
      "post crfb unet out shape:   torch.Size([1, 32, 16, 16])\n",
      "crfb2 shape:  torch.Size([1, 32, 256, 256])\n",
      "post crfb kinet out shape:  torch.Size([1, 32, 256, 256])\n",
      "skip unet shape:   torch.Size([1, 32, 16, 16])\n",
      "skip kinet shape:  torch.Size([1, 32, 256, 256])\n",
      "2\n",
      "unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "------------------\n",
      "\n",
      "crfb1 shape:  torch.Size([1, 16, 128, 128])\n",
      "post crfb unet out shape:   torch.Size([1, 16, 32, 32])\n",
      "crfb2 shape:  torch.Size([1, 16, 128, 128])\n",
      "post crfb kinet out shape:  torch.Size([1, 16, 128, 128])\n",
      "skip unet shape:   torch.Size([1, 16, 32, 32])\n",
      "skip kinet shape:  torch.Size([1, 16, 128, 128])\n",
      "3\n",
      "unet out shape:   torch.Size([1, 8, 64, 64])\n",
      "kinet out shape:  torch.Size([1, 8, 64, 64])\n",
      "------------------\n",
      "\n",
      "crfb1 shape:  torch.Size([1, 8, 64, 64])\n",
      "post crfb unet out shape:   torch.Size([1, 8, 64, 64])\n",
      "crfb2 shape:  torch.Size([1, 8, 64, 64])\n",
      "post crfb kinet out shape:  torch.Size([1, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y = kiunet(x.to(\"cuda\")).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d91f05b2-93c8-4c89-987a-ebafae7140fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2aba427-5816-44de-8422-5ad0463cd989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kiunet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.encoder1 = nn.Conv2d(1, 16, 3, stride=1, padding=1)  # First Layer GrayScale Image , change to input channels to 3 in case of RGB \n",
    "        self.en1_bn = nn.BatchNorm2d(16)\n",
    "        self.encoder2=   nn.Conv2d(16, 32, 3, stride=1, padding=1)  \n",
    "        self.en2_bn = nn.BatchNorm2d(32)\n",
    "        self.encoder3=   nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.en3_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.decoder1 =   nn.Conv2d(64, 32, 3, stride=1, padding=1)   \n",
    "        self.de1_bn = nn.BatchNorm2d(32)\n",
    "        self.decoder2 =   nn.Conv2d(32,16, 3, stride=1, padding=1)\n",
    "        self.de2_bn = nn.BatchNorm2d(16)\n",
    "        self.decoder3 =   nn.Conv2d(16, 8, 3, stride=1, padding=1)\n",
    "        self.de3_bn = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.decoderf1 =   nn.Conv2d(64, 32, 3, stride=1, padding=1)\n",
    "        self.def1_bn = nn.BatchNorm2d(32)\n",
    "        self.decoderf2=   nn.Conv2d(32, 16, 3, stride=1, padding=1)\n",
    "        self.def2_bn = nn.BatchNorm2d(16)\n",
    "        self.decoderf3 =   nn.Conv2d(16, 8, 3, stride=1, padding=1)\n",
    "        self.def3_bn = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.encoderf1 =   nn.Conv2d(1, 16, 3, stride=1, padding=1)  # First Layer GrayScale Image , change to input channels to 3 in case of RGB \n",
    "        self.enf1_bn = nn.BatchNorm2d(16)\n",
    "        self.encoderf2=   nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "        self.enf2_bn = nn.BatchNorm2d(32)\n",
    "        self.encoderf3 =   nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.enf3_bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.intere1_1 = nn.Conv2d(16,16,3, stride=1, padding=1)\n",
    "        self.inte1_1bn = nn.BatchNorm2d(16)\n",
    "        self.intere2_1 = nn.Conv2d(32,32,3, stride=1, padding=1)\n",
    "        self.inte2_1bn = nn.BatchNorm2d(32)\n",
    "        self.intere3_1 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.inte3_1bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.intere1_2 = nn.Conv2d(16,16,3, stride=1, padding=1)\n",
    "        self.inte1_2bn = nn.BatchNorm2d(16)\n",
    "        self.intere2_2 = nn.Conv2d(32,32,3, stride=1, padding=1)\n",
    "        self.inte2_2bn = nn.BatchNorm2d(32)\n",
    "        self.intere3_2 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.inte3_2bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.interd1_1 = nn.Conv2d(32,32,3, stride=1, padding=1)\n",
    "        self.intd1_1bn = nn.BatchNorm2d(32)\n",
    "        self.interd2_1 = nn.Conv2d(16,16,3, stride=1, padding=1)\n",
    "        self.intd2_1bn = nn.BatchNorm2d(16)\n",
    "        self.interd3_1 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.intd3_1bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.interd1_2 = nn.Conv2d(32,32,3, stride=1, padding=1)\n",
    "        self.intd1_2bn = nn.BatchNorm2d(32)\n",
    "        self.interd2_2 = nn.Conv2d(16,16,3, stride=1, padding=1)\n",
    "        self.intd2_2bn = nn.BatchNorm2d(16)\n",
    "        self.interd3_2 = nn.Conv2d(64,64,3, stride=1, padding=1)\n",
    "        self.intd3_2bn = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.final = nn.Conv2d(8,2,1,stride=1,padding=0)\n",
    "        \n",
    "        self.soft = nn.Softmax(dim =1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = F.relu(self.en1_bn(F.max_pool2d(self.encoder1(x),2,2)))  #U-Net branch\n",
    "        out1 = F.relu(self.enf1_bn(F.interpolate(self.encoderf1(x),scale_factor=(2,2),mode ='bilinear'))) #Ki-Net branch\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.inte1_1bn(self.intere1_1(out1))),scale_factor=(0.25,0.25),mode ='bilinear')) #CRFB\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.inte1_2bn(self.intere1_2(tmp))),scale_factor=(4,4),mode ='bilinear')) #CRFB\n",
    "        \n",
    "        u1 = out  #skip conn\n",
    "        o1 = out1  #skip conn\n",
    "\n",
    "        out = F.relu(self.en2_bn(F.max_pool2d(self.encoder2(out),2,2)))\n",
    "        out1 = F.relu(self.enf2_bn(F.interpolate(self.encoderf2(out1),scale_factor=(2,2),mode ='bilinear')))\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.inte2_1bn(self.intere2_1(out1))),scale_factor=(0.0625,0.0625),mode ='bilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.inte2_2bn(self.intere2_2(tmp))),scale_factor=(16,16),mode ='bilinear'))\n",
    "        \n",
    "        u2 = out\n",
    "        o2 = out1\n",
    "\n",
    "        out = F.relu(self.en3_bn(F.max_pool2d(self.encoder3(out),2,2)))\n",
    "        out1 = F.relu(self.enf3_bn(F.interpolate(self.encoderf3(out1),scale_factor=(2,2),mode ='bilinear')))\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.inte3_1bn(self.intere3_1(out1))),scale_factor=(0.015625,0.015625),mode ='bilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.inte3_2bn(self.intere3_2(tmp))),scale_factor=(64,64),mode ='bilinear'))\n",
    "        \n",
    "        ### End of encoder block\n",
    "\n",
    "        ### Start Decoder\n",
    "        print(\"unet shape\", out.shape)\n",
    "        print(\"kinet shape\", out1.shape)\n",
    "        \n",
    "        out = F.relu(self.de1_bn(F.interpolate(self.decoder1(out),scale_factor=(2,2),mode ='bilinear')))  #U-NET\n",
    "        out1 = F.relu(self.def1_bn(F.max_pool2d(self.decoderf1(out1),2,2))) #Ki-NET\n",
    "        print(\"\\nunet shape step 1\", out.shape)\n",
    "        print(\"kinet shape step 1\", out1.shape)\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.intd1_1bn(self.interd1_1(out1))),scale_factor=(0.0625,0.0625),mode ='bilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.intd1_2bn(self.interd1_2(tmp))),scale_factor=(16,16),mode ='bilinear'))\n",
    "        print(\"\\nunet shape crfb 1\", out.shape)\n",
    "        print(\"kinet shape crfb 1\", out1.shape)\n",
    "        \n",
    "        out = torch.add(out,u2)  #skip conn\n",
    "        out1 = torch.add(out1,o2)  #skip conn\n",
    "\n",
    "        out = F.relu(self.de2_bn(F.interpolate(self.decoder2(out),scale_factor=(2,2),mode ='bilinear')))\n",
    "        out1 = F.relu(self.def2_bn(F.max_pool2d(self.decoderf2(out1),2,2)))\n",
    "        tmp = out\n",
    "        out = torch.add(out,F.interpolate(F.relu(self.intd2_1bn(self.interd2_1(out1))),scale_factor=(0.25,0.25),mode ='bilinear'))\n",
    "        out1 = torch.add(out1,F.interpolate(F.relu(self.intd2_2bn(self.interd2_2(tmp))),scale_factor=(4,4),mode ='bilinear'))\n",
    "        \n",
    "        out = torch.add(out,u1)\n",
    "        out1 = torch.add(out1,o1)\n",
    "\n",
    "        out = F.relu(self.de3_bn(F.interpolate(self.decoder3(out),scale_factor=(2,2),mode ='bilinear')))\n",
    "        out1 = F.relu(self.def3_bn(F.max_pool2d(self.decoderf3(out1),2,2)))\n",
    "\n",
    "        \n",
    "\n",
    "        out = torch.add(out,out1) # fusion of both branches\n",
    "\n",
    "        out = F.relu(self.final(out))  #1*1 conv\n",
    "        \n",
    "\n",
    "        # out = self.soft(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bad837a3-da75-49a2-8918-3ba00fc3ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiu = Kiunet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7267e932-d4fb-4f1a-a3a0-26b3f63dba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet shape torch.Size([4, 64, 16, 16])\n",
      "kinet shape torch.Size([4, 64, 1024, 1024])\n",
      "\n",
      "unet shape step 1 torch.Size([4, 32, 32, 32])\n",
      "kinet shape step 1 torch.Size([4, 32, 512, 512])\n",
      "\n",
      "unet shape crfb 1 torch.Size([4, 32, 32, 32])\n",
      "kinet shape crfb 1 torch.Size([4, 32, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Kiunet                                   --                        --\n",
       "├─Conv2d: 1-1                            [4, 16, 128, 128]         160\n",
       "├─BatchNorm2d: 1-2                       [4, 16, 64, 64]           32\n",
       "├─Conv2d: 1-3                            [4, 16, 128, 128]         160\n",
       "├─BatchNorm2d: 1-4                       [4, 16, 256, 256]         32\n",
       "├─Conv2d: 1-5                            [4, 16, 256, 256]         2,320\n",
       "├─BatchNorm2d: 1-6                       [4, 16, 256, 256]         32\n",
       "├─Conv2d: 1-7                            [4, 16, 64, 64]           2,320\n",
       "├─BatchNorm2d: 1-8                       [4, 16, 64, 64]           32\n",
       "├─Conv2d: 1-9                            [4, 32, 64, 64]           4,640\n",
       "├─BatchNorm2d: 1-10                      [4, 32, 32, 32]           64\n",
       "├─Conv2d: 1-11                           [4, 32, 256, 256]         4,640\n",
       "├─BatchNorm2d: 1-12                      [4, 32, 512, 512]         64\n",
       "├─Conv2d: 1-13                           [4, 32, 512, 512]         9,248\n",
       "├─BatchNorm2d: 1-14                      [4, 32, 512, 512]         64\n",
       "├─Conv2d: 1-15                           [4, 32, 32, 32]           9,248\n",
       "├─BatchNorm2d: 1-16                      [4, 32, 32, 32]           64\n",
       "├─Conv2d: 1-17                           [4, 64, 32, 32]           18,496\n",
       "├─BatchNorm2d: 1-18                      [4, 64, 16, 16]           128\n",
       "├─Conv2d: 1-19                           [4, 64, 512, 512]         18,496\n",
       "├─BatchNorm2d: 1-20                      [4, 64, 1024, 1024]       128\n",
       "├─Conv2d: 1-21                           [4, 64, 1024, 1024]       36,928\n",
       "├─BatchNorm2d: 1-22                      [4, 64, 1024, 1024]       128\n",
       "├─Conv2d: 1-23                           [4, 64, 16, 16]           36,928\n",
       "├─BatchNorm2d: 1-24                      [4, 64, 16, 16]           128\n",
       "├─Conv2d: 1-25                           [4, 32, 16, 16]           18,464\n",
       "├─BatchNorm2d: 1-26                      [4, 32, 32, 32]           64\n",
       "├─Conv2d: 1-27                           [4, 32, 1024, 1024]       18,464\n",
       "├─BatchNorm2d: 1-28                      [4, 32, 512, 512]         64\n",
       "├─Conv2d: 1-29                           [4, 32, 512, 512]         9,248\n",
       "├─BatchNorm2d: 1-30                      [4, 32, 512, 512]         64\n",
       "├─Conv2d: 1-31                           [4, 32, 32, 32]           9,248\n",
       "├─BatchNorm2d: 1-32                      [4, 32, 32, 32]           64\n",
       "├─Conv2d: 1-33                           [4, 16, 32, 32]           4,624\n",
       "├─BatchNorm2d: 1-34                      [4, 16, 64, 64]           32\n",
       "├─Conv2d: 1-35                           [4, 16, 512, 512]         4,624\n",
       "├─BatchNorm2d: 1-36                      [4, 16, 256, 256]         32\n",
       "├─Conv2d: 1-37                           [4, 16, 256, 256]         2,320\n",
       "├─BatchNorm2d: 1-38                      [4, 16, 256, 256]         32\n",
       "├─Conv2d: 1-39                           [4, 16, 64, 64]           2,320\n",
       "├─BatchNorm2d: 1-40                      [4, 16, 64, 64]           32\n",
       "├─Conv2d: 1-41                           [4, 8, 64, 64]            1,160\n",
       "├─BatchNorm2d: 1-42                      [4, 8, 128, 128]          16\n",
       "├─Conv2d: 1-43                           [4, 8, 256, 256]          1,160\n",
       "├─BatchNorm2d: 1-44                      [4, 8, 128, 128]          16\n",
       "├─Conv2d: 1-45                           [4, 2, 128, 128]          18\n",
       "├─BatchNorm2d: 1-46                      --                        (recursive)\n",
       "├─Conv2d: 1-47                           --                        36,928\n",
       "├─BatchNorm2d: 1-48                      --                        128\n",
       "├─Conv2d: 1-49                           --                        (recursive)\n",
       "├─Softmax: 1-50                          --                        --\n",
       "==========================================================================================\n",
       "Total params: 253,602\n",
       "Trainable params: 253,602\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 279.13\n",
       "==========================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 10137.89\n",
       "Params size (MB): 1.01\n",
       "Estimated Total Size (MB): 10139.17\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(kiu, (4, 1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde101dc-8ccb-4109-8cb8-65b7565b9d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
